{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FrozenLake-v0\n",
    "\n",
    "The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile.\n",
    "\n",
    "The episode ends when you reach the goal or fall in a hole. You receive a reward of 1 if you reach the goal, and zero otherwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Q-learning\n",
    "\n",
    "Q learning is a type of value-based RL algorithm. Say we had a situation like the one below. We have a robot, that has to go till the end, avoiding the obstacles. Lets say hitting any obstacle gives you a negative reward of -10. Lets say getting to the end gives you a +50 reward. Each step gives you a negative reward of -1, because the goal is to get to the end as quick as possible. \n",
    "\n",
    "### The Q-table\n",
    "\n",
    "A Q-table is just a table that maps out the maximum expected future reward, for each action at each state. Going back to the previous example, a state would just be a block, and an action would basically be which direction you choose to move in from that block. There are 4 possible actions at each state, moving left, right, down, or up.\n",
    "\n",
    "The Q-table is basically a cheat-sheet for the agent that tells it which action is the best action to take from each state. The Q-table itself improves with each iteration of the game. \n",
    "\n",
    "\n",
    "### Q-learning Algorithm \n",
    "\n",
    "The Q function has 2 inputs, the state and the action and based on this it computes the maximum expected future reward. Here is the equation for it:\n",
    "\n",
    "Q-learning can be implemented as follows:\n",
    "\n",
    "Q(s,a)+=α⋅[r+γ⋅maxαQ(s′)−Q(s,a)]\n",
    "s: is the previous state\n",
    "\n",
    "a: is the previous action\n",
    "\n",
    "Q(): is the Q-learning algorithm\n",
    "\n",
    "s’: is the current state\n",
    "\n",
    "alpha: is the learning rate, set generally between 0 and 1. Setting the alpha value to 0 means that the Q-values are never updated, thereby nothing is learned. If we set the alpha to a high value such as 0.9, it means that the learning can occur quickly.\n",
    "\n",
    "gamma: It is the discount factor that is set between 0 and 1. This model the fact that future rewards are worth less than immediate rewards.\n",
    "\n",
    "max: is the maximum reward that is attainable in the state following the current one (the reward for taking the optimal action thereafter).\n",
    "\n",
    "The algorithm can be interpreted as:\n",
    "\n",
    "Initialize the Q-values table, Q(s, a).\n",
    "\n",
    "Observe the current state, s.\n",
    "\n",
    "Take an action, a, for that state based on the selection policy.\n",
    "\n",
    "Pick that action, and observe the reward, r, as well as the new state, s’.\n",
    "\n",
    "Now update the Q-value for the state with the help of the observed reward and the maximum reward possible for the next state.\n",
    "\n",
    "Place the state to the new state, and repeat the process until a terminal state is reached.\n",
    "\n",
    "Thus, alpha is the learning rate. If the reward or transition function is random, then alpha should change over the period, approaching zero at infinity. This has to effect approximating the expected outcome of an inner product (T(transition)*R(reward)), when one of the two, or both, has random behavior.\n",
    "\n",
    "Whereas, gamma is the value of future rewards. It can change the learning quite a bit and can be a dynamic or static value. If it is equal to one, the agent values future reward JUST AS MUCH as a current reward. This means, in ten actions, if an agent does something good this is JUST AS VALUABLE as doing this action directly. So learning doesn't work well at high gamma values.\n",
    "\n",
    "Similarly, a gamma of zero will cause the agent to only value immediate rewards, which only works with very detailed reward functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "from IPython.display import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'N:\\ADVANCE DATA SCIENCE\\ASSIGNMENTS\\Assignment 2')\n",
    "Image('Frozen-Lake.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Number of Episodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Training Episodes - 2500\n",
      "Training Score over time: 0.0\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 17.68\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Training Episodes - 5000\n",
      "Training Score over time: 0.0\n",
      "Average Epsilon value when max steps is reached: 0.010004520962274964\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 19.21\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Training Episodes - 10000\n",
      "Training Score over time: 0.315\n",
      "Average Epsilon value when max steps is reached: 0.010043804032128045\n",
      "[[1.81374945e-03 2.36871670e-04 2.06222590e-04 2.93945497e-04]\n",
      " [1.44753262e-05 2.45814548e-05 7.39824375e-05 1.85789631e-04]\n",
      " [6.25667499e-05 1.23044457e-04 1.39682708e-03 5.79920245e-05]\n",
      " [4.35117677e-05 2.26449471e-07 1.85766725e-04 8.58003929e-04]\n",
      " [5.13948799e-03 3.35696834e-04 1.23274258e-04 5.08194563e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.26402319e-06 3.58835011e-07 4.86474152e-04 2.00718466e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.40793386e-04 7.70288924e-04 1.60547987e-03 4.36787641e-02]\n",
      " [3.92755258e-03 5.32380163e-03 4.89689276e-02 4.01867511e-03]\n",
      " [3.31637231e-03 2.72784847e-01 9.83679171e-04 3.67055029e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.00111614e-03 4.41836085e-03 5.34364518e-01 7.31107253e-03]\n",
      " [4.01338329e-02 3.02822604e-02 9.79754266e-01 3.95712387e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.18\n",
      "Average num of Steps Per Episode: 23.53\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Episodes - 15000\n",
      "Training Score over time: 0.31666666666666665\n",
      "Average Epsilon value when max steps is reached: 0.01001374961094748\n",
      "[[2.48373727e-03 6.80288716e-03 2.64429074e-03 1.89243012e-03]\n",
      " [7.60651350e-04 1.70757343e-05 1.60464563e-03 7.44077348e-03]\n",
      " [1.50005866e-03 5.43234536e-04 1.03281011e-01 5.81464913e-04]\n",
      " [3.07186454e-03 2.26045199e-04 5.93384774e-06 9.70494386e-03]\n",
      " [5.65207338e-03 1.15523285e-03 1.98891598e-04 1.42390019e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.07735853e-01 1.93977423e-05 8.22038731e-06 2.79723458e-08]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.72119643e-03 1.49672607e-04 6.82105816e-03 6.04245438e-03]\n",
      " [1.03678049e-03 1.11455487e-01 3.97114645e-03 6.64411068e-03]\n",
      " [4.06496259e-01 3.22741000e-04 1.50184292e-03 5.55694625e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.34574362e-02 3.57436806e-03 5.29683908e-01 7.04274773e-03]\n",
      " [2.27586654e-02 4.45509606e-01 6.23489719e-01 3.02800746e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  1.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.15\n",
      "Average num of Steps Per Episode: 17.44\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Training Episodes - 25000\n",
      "Training Score over time: 0.31988\n",
      "Average Epsilon value when max steps is reached: 0.010028045610651477\n",
      "[[1.17225528e-03 1.27343993e-03 2.78642872e-03 1.28493763e-03]\n",
      " [3.92019969e-04 9.98350749e-04 3.22051428e-04 1.03650525e-03]\n",
      " [7.61245428e-04 4.23867131e-04 4.97688381e-04 4.34802032e-04]\n",
      " [6.39861455e-06 4.71399729e-05 5.22070172e-05 6.18976516e-04]\n",
      " [1.10286128e-02 2.69767127e-03 1.22174538e-03 9.11864195e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.34147589e-04 9.99816061e-05 1.90307989e-04 1.14494553e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.07838668e-04 2.68859605e-03 1.00697772e-03 2.68092030e-02]\n",
      " [7.53570977e-03 2.26190777e-02 2.97031385e-03 1.25277125e-02]\n",
      " [1.46012802e-02 7.34724188e-03 1.37940021e-03 1.72780914e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.52316002e-02 1.40684024e-02 2.97963265e-02 4.80661566e-03]\n",
      " [3.54406445e-02 9.79675330e-02 7.74000585e-01 2.18927102e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.39\n",
      "Average num of Steps Per Episode: 24.64\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Episodes - 50000\n",
      "Training Score over time: 0.32678\n",
      "Average Epsilon value when max steps is reached: 0.010052218824367376\n",
      "[[3.68383707e-02 4.59537101e-04 5.30252258e-04 5.24228391e-04]\n",
      " [3.29594158e-04 2.18258799e-04 2.10695023e-04 4.49415442e-04]\n",
      " [2.26216416e-04 4.95948838e-04 3.90965563e-04 4.45778623e-04]\n",
      " [1.42739658e-04 1.48124867e-04 5.34537264e-05 1.66908970e-04]\n",
      " [9.77811173e-02 7.61494167e-04 6.26196325e-04 1.72905666e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.45496809e-07 1.10355386e-08 1.40751848e-04 5.29091715e-08]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.57681432e-03 3.30934336e-03 1.00674319e-03 3.15902771e-01]\n",
      " [1.43514543e-02 4.80949326e-01 3.34925199e-02 1.72071088e-02]\n",
      " [4.68646133e-01 1.26585081e-03 5.88596268e-03 3.96965973e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.89387121e-03 2.16549359e-03 6.23624985e-01 1.11163613e-02]\n",
      " [1.42062863e-01 1.39332950e-01 9.63012012e-01 7.56164722e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.65\n",
      "Average num of Steps Per Episode: 41.6\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Training Episodes - 70000\n",
      "Training Score over time: 0.32435714285714284\n",
      "Average Epsilon value when max steps is reached: 0.010012939582932317\n",
      "[[1.11336945e-03 9.82456011e-04 1.87595916e-02 1.27081046e-03]\n",
      " [2.70980976e-05 6.04790508e-04 1.75711136e-04 1.01318363e-02]\n",
      " [8.75710197e-03 6.40787976e-05 1.47615998e-04 4.21663381e-04]\n",
      " [4.30040896e-05 6.92482535e-05 1.71811311e-05 9.65044413e-05]\n",
      " [2.91992031e-02 3.62312137e-04 9.95649026e-04 6.01336958e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.35589220e-04 1.65397043e-07 2.86674891e-03 1.54838474e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.45359872e-03 4.53150484e-03 1.23168123e-02 1.03941337e-01]\n",
      " [3.29023692e-04 1.07774090e-01 3.23645583e-03 1.59247676e-03]\n",
      " [1.29771783e-01 1.16240295e-03 1.70928114e-03 1.31914111e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.68564088e-03 9.86237459e-03 2.61728030e-02 4.68022134e-01]\n",
      " [8.25906543e-03 9.31337664e-01 1.80437493e-01 7.58812694e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.22\n",
      "Average num of Steps Per Episode: 25.55\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [2500, 5000, 10000, 15000, 25000, 50000, 70000]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "\n",
    "    total_episodes = param        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 99                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7           # Learning rate\n",
    "    gamma = 0.8                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1.0                 # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = 0.01             # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Training Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Learning Rate value - \" + str(learning_rate))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best testing score is 0.65 with Number of Episodes = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Maximum Steps (using the best parameters from previous runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Max Steps - 50\n",
      "Training Score over time: 0.0\n",
      "Average Epsilon value when max steps is reached: 0.010178107198008015\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 18.2\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Max Steps - 100\n",
      "Training Score over time: 0.32038\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.22943527e-02 1.33112322e-03 1.31577916e-03 1.49033258e-03]\n",
      " [1.91723206e-04 1.05058800e-04 4.62741253e-04 1.32855873e-03]\n",
      " [1.56928531e-03 1.38079671e-03 1.30954629e-03 1.47757667e-03]\n",
      " [3.14699527e-06 2.50989666e-04 2.28695076e-04 1.31951160e-03]\n",
      " [2.85731383e-02 5.82853567e-04 1.20067465e-03 4.82202754e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.96109327e-05 1.98797987e-06 1.98226901e-03 8.29507667e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.46906369e-03 6.03032204e-04 2.47067241e-04 7.68467500e-02]\n",
      " [3.08095096e-04 8.28703295e-02 2.89527925e-02 1.57305079e-02]\n",
      " [6.09579472e-01 7.75204813e-05 2.12359578e-03 1.46115873e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.37847721e-03 4.75635100e-03 2.05705167e-01 4.46476635e-02]\n",
      " [3.47972320e-02 7.96228271e-01 5.78482483e-02 5.85608205e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.75\n",
      "Average num of Steps Per Episode: 35.6\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Max Steps - 200\n",
      "Training Score over time: 0.32046\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[2.49085550e-04 1.74459997e-03 1.13550029e-02 1.61411622e-03]\n",
      " [9.28927149e-04 3.06734730e-05 3.55982970e-04 6.88157208e-03]\n",
      " [3.11550449e-04 4.42108258e-03 2.46498676e-03 3.77521188e-05]\n",
      " [5.77840881e-05 1.38687533e-04 3.94936741e-05 2.41715996e-03]\n",
      " [2.43568457e-02 2.21132484e-03 6.29242401e-04 1.29982886e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.69660112e-05 3.08874360e-08 1.19718668e-03 1.21582402e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.56706378e-03 1.28410050e-03 2.89781680e-03 7.88663349e-02]\n",
      " [3.16764295e-03 1.80903070e-01 9.79937701e-03 6.90777153e-03]\n",
      " [1.50758498e-01 7.27706902e-04 4.56772476e-04 2.29789298e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.32131450e-02 2.27764233e-02 3.47953339e-01 1.93066029e-02]\n",
      " [6.54802828e-02 2.67525858e-02 7.91136529e-01 8.48663095e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  1.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.43\n",
      "Average num of Steps Per Episode: 35.78\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Max Steps - 400\n",
      "Training Score over time: 0.32808\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[6.82113332e-02 1.76861437e-04 1.14246325e-04 1.85956727e-04]\n",
      " [6.18420669e-05 6.86092109e-05 2.98722068e-05 5.03471916e-03]\n",
      " [6.85394813e-05 6.52106120e-05 6.47372573e-05 2.46068376e-04]\n",
      " [2.70098087e-05 2.59175037e-05 4.00055608e-05 5.86491821e-05]\n",
      " [7.53997445e-02 4.25305510e-04 5.09871532e-04 5.81221288e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.63134103e-05 9.89459129e-06 2.84240590e-03 2.28857207e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.24755930e-04 1.64310496e-03 1.80000944e-03 8.37159586e-02]\n",
      " [3.13365861e-03 3.76106621e-01 7.13762008e-03 2.01710529e-04]\n",
      " [7.42267857e-01 2.41700290e-03 1.20398042e-03 5.51159151e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.18446667e-03 5.63204045e-01 2.86431679e-02 6.27524522e-03]\n",
      " [2.32114945e-02 2.84985002e-02 2.88421741e-02 9.99507289e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.26\n",
      "Average num of Steps Per Episode: 33.52\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Max Steps - 500\n",
      "Training Score over time: 0.32612\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[7.45283585e-04 3.02446658e-04 5.64941680e-04 3.00850829e-04]\n",
      " [3.44554652e-04 5.60477915e-05 1.71782621e-06 8.84478206e-04]\n",
      " [1.32451065e-03 2.16462317e-04 1.91689377e-04 2.46145781e-04]\n",
      " [1.20660128e-04 1.29597076e-05 5.19444243e-06 1.26411299e-02]\n",
      " [8.06746365e-04 7.50061492e-04 2.59960603e-04 3.08308427e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.75653712e-07 1.67921090e-06 6.21813856e-02 2.48757248e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.22005157e-04 1.09778486e-05 1.28774246e-04 7.16178895e-04]\n",
      " [7.95302955e-04 2.55698361e-02 5.20481528e-04 2.25698136e-03]\n",
      " [1.48864198e-01 1.81233701e-03 6.49791445e-03 1.11916140e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.54182166e-03 1.09697936e-03 4.41465146e-03 8.56277689e-02]\n",
      " [2.38742374e-02 2.43612461e-02 2.19372568e-02 7.42625036e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  1.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.37\n",
      "Average num of Steps Per Episode: 34.66\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [50, 100, 200, 400, 500]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = param                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7           # Learning rate\n",
    "    gamma = 0.8                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1.0                 # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = 0.01             # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Max Steps - \" + str(max_steps))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Learning Rate value - \" + str(learning_rate))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running it for more number of Test Episodes for Validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Max Steps - 50\n",
      "Training Score over time: 0.0\n",
      "Average Epsilon value when max steps is reached: 0.010083566929513902\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Episode - 100,  Score -  0.0\n",
      "Episode - 101,  Score -  0.0\n",
      "Episode - 102,  Score -  0.0\n",
      "Episode - 103,  Score -  0.0\n",
      "Episode - 104,  Score -  0.0\n",
      "Episode - 105,  Score -  0.0\n",
      "Episode - 106,  Score -  0.0\n",
      "Episode - 107,  Score -  0.0\n",
      "Episode - 109,  Score -  0.0\n",
      "Episode - 110,  Score -  0.0\n",
      "Episode - 111,  Score -  0.0\n",
      "Episode - 112,  Score -  0.0\n",
      "Episode - 113,  Score -  0.0\n",
      "Episode - 114,  Score -  0.0\n",
      "Episode - 115,  Score -  0.0\n",
      "Episode - 116,  Score -  0.0\n",
      "Episode - 117,  Score -  0.0\n",
      "Episode - 118,  Score -  0.0\n",
      "Episode - 119,  Score -  0.0\n",
      "Episode - 120,  Score -  0.0\n",
      "Episode - 121,  Score -  0.0\n",
      "Episode - 122,  Score -  0.0\n",
      "Episode - 123,  Score -  0.0\n",
      "Episode - 124,  Score -  0.0\n",
      "Episode - 125,  Score -  0.0\n",
      "Episode - 126,  Score -  0.0\n",
      "Episode - 127,  Score -  0.0\n",
      "Episode - 128,  Score -  0.0\n",
      "Episode - 129,  Score -  0.0\n",
      "Episode - 130,  Score -  0.0\n",
      "Episode - 131,  Score -  0.0\n",
      "Episode - 132,  Score -  0.0\n",
      "Episode - 133,  Score -  0.0\n",
      "Episode - 134,  Score -  0.0\n",
      "Episode - 135,  Score -  0.0\n",
      "Episode - 136,  Score -  0.0\n",
      "Episode - 137,  Score -  0.0\n",
      "Episode - 138,  Score -  0.0\n",
      "Episode - 139,  Score -  0.0\n",
      "Episode - 140,  Score -  0.0\n",
      "Episode - 141,  Score -  0.0\n",
      "Episode - 142,  Score -  0.0\n",
      "Episode - 143,  Score -  0.0\n",
      "Episode - 144,  Score -  0.0\n",
      "Episode - 145,  Score -  0.0\n",
      "Episode - 146,  Score -  0.0\n",
      "Episode - 147,  Score -  0.0\n",
      "Episode - 148,  Score -  0.0\n",
      "Episode - 149,  Score -  0.0\n",
      "Episode - 151,  Score -  0.0\n",
      "Episode - 152,  Score -  0.0\n",
      "Episode - 153,  Score -  0.0\n",
      "Episode - 154,  Score -  0.0\n",
      "Episode - 155,  Score -  0.0\n",
      "Episode - 156,  Score -  0.0\n",
      "Episode - 157,  Score -  0.0\n",
      "Episode - 158,  Score -  0.0\n",
      "Episode - 159,  Score -  0.0\n",
      "Episode - 160,  Score -  0.0\n",
      "Episode - 161,  Score -  0.0\n",
      "Episode - 162,  Score -  0.0\n",
      "Episode - 163,  Score -  0.0\n",
      "Episode - 164,  Score -  0.0\n",
      "Episode - 165,  Score -  0.0\n",
      "Episode - 166,  Score -  0.0\n",
      "Episode - 167,  Score -  0.0\n",
      "Episode - 168,  Score -  0.0\n",
      "Episode - 169,  Score -  0.0\n",
      "Episode - 170,  Score -  0.0\n",
      "Episode - 171,  Score -  0.0\n",
      "Episode - 172,  Score -  0.0\n",
      "Episode - 173,  Score -  0.0\n",
      "Episode - 174,  Score -  0.0\n",
      "Episode - 175,  Score -  0.0\n",
      "Episode - 176,  Score -  0.0\n",
      "Episode - 177,  Score -  0.0\n",
      "Episode - 178,  Score -  0.0\n",
      "Episode - 179,  Score -  0.0\n",
      "Episode - 180,  Score -  0.0\n",
      "Episode - 181,  Score -  0.0\n",
      "Episode - 182,  Score -  0.0\n",
      "Episode - 183,  Score -  0.0\n",
      "Episode - 184,  Score -  0.0\n",
      "Episode - 185,  Score -  0.0\n",
      "Episode - 186,  Score -  0.0\n",
      "Episode - 187,  Score -  0.0\n",
      "Episode - 188,  Score -  0.0\n",
      "Episode - 189,  Score -  0.0\n",
      "Episode - 190,  Score -  0.0\n",
      "Episode - 191,  Score -  0.0\n",
      "Episode - 192,  Score -  0.0\n",
      "Episode - 193,  Score -  0.0\n",
      "Episode - 194,  Score -  0.0\n",
      "Episode - 195,  Score -  0.0\n",
      "Episode - 196,  Score -  0.0\n",
      "Episode - 197,  Score -  0.0\n",
      "Episode - 198,  Score -  0.0\n",
      "Episode - 199,  Score -  0.0\n",
      "Episode - 200,  Score -  0.0\n",
      "Episode - 201,  Score -  0.0\n",
      "Episode - 202,  Score -  0.0\n",
      "Episode - 203,  Score -  0.0\n",
      "Episode - 204,  Score -  0.0\n",
      "Episode - 205,  Score -  0.0\n",
      "Episode - 206,  Score -  0.0\n",
      "Episode - 207,  Score -  0.0\n",
      "Episode - 208,  Score -  0.0\n",
      "Episode - 209,  Score -  0.0\n",
      "Episode - 210,  Score -  0.0\n",
      "Episode - 211,  Score -  0.0\n",
      "Episode - 212,  Score -  0.0\n",
      "Episode - 213,  Score -  0.0\n",
      "Episode - 214,  Score -  0.0\n",
      "Episode - 215,  Score -  0.0\n",
      "Episode - 216,  Score -  0.0\n",
      "Episode - 217,  Score -  0.0\n",
      "Episode - 218,  Score -  0.0\n",
      "Episode - 219,  Score -  0.0\n",
      "Episode - 220,  Score -  0.0\n",
      "Episode - 221,  Score -  0.0\n",
      "Episode - 222,  Score -  0.0\n",
      "Episode - 223,  Score -  0.0\n",
      "Episode - 224,  Score -  0.0\n",
      "Episode - 225,  Score -  0.0\n",
      "Episode - 226,  Score -  0.0\n",
      "Episode - 227,  Score -  0.0\n",
      "Episode - 228,  Score -  0.0\n",
      "Episode - 229,  Score -  0.0\n",
      "Episode - 230,  Score -  0.0\n",
      "Episode - 231,  Score -  0.0\n",
      "Episode - 232,  Score -  0.0\n",
      "Episode - 233,  Score -  0.0\n",
      "Episode - 234,  Score -  0.0\n",
      "Episode - 235,  Score -  0.0\n",
      "Episode - 236,  Score -  0.0\n",
      "Episode - 237,  Score -  0.0\n",
      "Episode - 238,  Score -  0.0\n",
      "Episode - 239,  Score -  0.0\n",
      "Episode - 240,  Score -  0.0\n",
      "Episode - 241,  Score -  0.0\n",
      "Episode - 242,  Score -  0.0\n",
      "Episode - 243,  Score -  0.0\n",
      "Episode - 244,  Score -  0.0\n",
      "Episode - 245,  Score -  0.0\n",
      "Episode - 246,  Score -  0.0\n",
      "Episode - 247,  Score -  0.0\n",
      "Episode - 248,  Score -  0.0\n",
      "Episode - 249,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 250\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 15.524\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Max Steps - 100\n",
      "Training Score over time: 0.32966\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[3.78612571e-03 3.75434588e-03 5.48198378e-04 7.69528874e-04]\n",
      " [1.14401771e-05 1.71903042e-04 3.54118930e-04 3.25757124e-03]\n",
      " [2.85166823e-04 1.52176556e-04 2.13958011e-04 2.47387972e-04]\n",
      " [7.65956296e-06 2.98088231e-05 3.71421480e-05 1.07333075e-04]\n",
      " [1.86555122e-02 2.36949890e-04 7.52933960e-05 1.57021791e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.21168219e-02 3.17045667e-05 5.32736578e-05 1.11859288e-08]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.88917945e-03 1.14235544e-02 4.41429318e-04 5.21211934e-02]\n",
      " [3.60819229e-03 2.09979049e-01 6.93483594e-02 4.17114176e-03]\n",
      " [7.24594321e-01 3.17880430e-07 8.12378637e-04 1.37859332e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.90651023e-02 7.54764153e-03 2.92081936e-01 7.08119145e-03]\n",
      " [5.37375054e-02 8.04717825e-01 7.03696432e-02 6.09766095e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Episode - 100,  Score -  0.0\n",
      "Episode - 101,  Score -  0.0\n",
      "Episode - 102,  Score -  1.0\n",
      "Episode - 103,  Score -  1.0\n",
      "Episode - 104,  Score -  1.0\n",
      "Episode - 105,  Score -  0.0\n",
      "Episode - 106,  Score -  1.0\n",
      "Episode - 107,  Score -  0.0\n",
      "Episode - 108,  Score -  0.0\n",
      "Episode - 109,  Score -  1.0\n",
      "Episode - 110,  Score -  1.0\n",
      "Episode - 111,  Score -  1.0\n",
      "Episode - 112,  Score -  0.0\n",
      "Episode - 113,  Score -  0.0\n",
      "Episode - 114,  Score -  0.0\n",
      "Episode - 115,  Score -  1.0\n",
      "Episode - 116,  Score -  0.0\n",
      "Episode - 117,  Score -  1.0\n",
      "Episode - 118,  Score -  0.0\n",
      "Episode - 119,  Score -  1.0\n",
      "Episode - 120,  Score -  1.0\n",
      "Episode - 121,  Score -  0.0\n",
      "Episode - 122,  Score -  0.0\n",
      "Episode - 123,  Score -  0.0\n",
      "Episode - 124,  Score -  1.0\n",
      "Episode - 125,  Score -  0.0\n",
      "Episode - 126,  Score -  0.0\n",
      "Episode - 127,  Score -  1.0\n",
      "Episode - 128,  Score -  1.0\n",
      "Episode - 129,  Score -  1.0\n",
      "Episode - 130,  Score -  1.0\n",
      "Episode - 131,  Score -  1.0\n",
      "Episode - 132,  Score -  1.0\n",
      "Episode - 133,  Score -  1.0\n",
      "Episode - 134,  Score -  0.0\n",
      "Episode - 135,  Score -  1.0\n",
      "Episode - 136,  Score -  1.0\n",
      "Episode - 137,  Score -  1.0\n",
      "Episode - 138,  Score -  0.0\n",
      "Episode - 139,  Score -  1.0\n",
      "Episode - 140,  Score -  0.0\n",
      "Episode - 141,  Score -  0.0\n",
      "Episode - 142,  Score -  0.0\n",
      "Episode - 143,  Score -  1.0\n",
      "Episode - 144,  Score -  0.0\n",
      "Episode - 145,  Score -  0.0\n",
      "Episode - 146,  Score -  1.0\n",
      "Episode - 147,  Score -  1.0\n",
      "Episode - 148,  Score -  1.0\n",
      "Episode - 149,  Score -  1.0\n",
      "Episode - 150,  Score -  1.0\n",
      "Episode - 151,  Score -  1.0\n",
      "Episode - 152,  Score -  1.0\n",
      "Episode - 153,  Score -  1.0\n",
      "Episode - 154,  Score -  0.0\n",
      "Episode - 155,  Score -  0.0\n",
      "Episode - 156,  Score -  0.0\n",
      "Episode - 157,  Score -  1.0\n",
      "Episode - 158,  Score -  1.0\n",
      "Episode - 159,  Score -  1.0\n",
      "Episode - 160,  Score -  1.0\n",
      "Episode - 161,  Score -  1.0\n",
      "Episode - 162,  Score -  0.0\n",
      "Episode - 163,  Score -  0.0\n",
      "Episode - 164,  Score -  0.0\n",
      "Episode - 165,  Score -  1.0\n",
      "Episode - 166,  Score -  1.0\n",
      "Episode - 167,  Score -  1.0\n",
      "Episode - 168,  Score -  1.0\n",
      "Episode - 169,  Score -  0.0\n",
      "Episode - 170,  Score -  1.0\n",
      "Episode - 171,  Score -  1.0\n",
      "Episode - 172,  Score -  1.0\n",
      "Episode - 173,  Score -  0.0\n",
      "Episode - 174,  Score -  1.0\n",
      "Episode - 175,  Score -  1.0\n",
      "Episode - 176,  Score -  1.0\n",
      "Episode - 177,  Score -  1.0\n",
      "Episode - 178,  Score -  1.0\n",
      "Episode - 179,  Score -  1.0\n",
      "Episode - 180,  Score -  0.0\n",
      "Episode - 181,  Score -  1.0\n",
      "Episode - 182,  Score -  1.0\n",
      "Episode - 183,  Score -  1.0\n",
      "Episode - 184,  Score -  0.0\n",
      "Episode - 185,  Score -  0.0\n",
      "Episode - 186,  Score -  0.0\n",
      "Episode - 187,  Score -  0.0\n",
      "Episode - 188,  Score -  1.0\n",
      "Episode - 189,  Score -  0.0\n",
      "Episode - 190,  Score -  0.0\n",
      "Episode - 191,  Score -  1.0\n",
      "Episode - 192,  Score -  0.0\n",
      "Episode - 193,  Score -  1.0\n",
      "Episode - 194,  Score -  0.0\n",
      "Episode - 195,  Score -  1.0\n",
      "Episode - 196,  Score -  0.0\n",
      "Episode - 197,  Score -  1.0\n",
      "Episode - 198,  Score -  1.0\n",
      "Episode - 199,  Score -  1.0\n",
      "Episode - 200,  Score -  1.0\n",
      "Episode - 201,  Score -  1.0\n",
      "Episode - 202,  Score -  1.0\n",
      "Episode - 203,  Score -  0.0\n",
      "Episode - 204,  Score -  1.0\n",
      "Episode - 205,  Score -  0.0\n",
      "Episode - 206,  Score -  1.0\n",
      "Episode - 207,  Score -  1.0\n",
      "Episode - 208,  Score -  0.0\n",
      "Episode - 209,  Score -  0.0\n",
      "Episode - 210,  Score -  0.0\n",
      "Episode - 211,  Score -  1.0\n",
      "Episode - 212,  Score -  1.0\n",
      "Episode - 213,  Score -  1.0\n",
      "Episode - 214,  Score -  1.0\n",
      "Episode - 215,  Score -  1.0\n",
      "Episode - 216,  Score -  1.0\n",
      "Episode - 217,  Score -  1.0\n",
      "Episode - 218,  Score -  1.0\n",
      "Episode - 219,  Score -  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode - 220,  Score -  1.0\n",
      "Episode - 221,  Score -  0.0\n",
      "Episode - 222,  Score -  1.0\n",
      "Episode - 223,  Score -  1.0\n",
      "Episode - 224,  Score -  0.0\n",
      "Episode - 225,  Score -  0.0\n",
      "Episode - 226,  Score -  0.0\n",
      "Episode - 227,  Score -  1.0\n",
      "Episode - 228,  Score -  1.0\n",
      "Episode - 229,  Score -  0.0\n",
      "Episode - 230,  Score -  1.0\n",
      "Episode - 231,  Score -  1.0\n",
      "Episode - 232,  Score -  1.0\n",
      "Episode - 233,  Score -  0.0\n",
      "Episode - 234,  Score -  1.0\n",
      "Episode - 235,  Score -  1.0\n",
      "Episode - 236,  Score -  1.0\n",
      "Episode - 237,  Score -  1.0\n",
      "Episode - 238,  Score -  1.0\n",
      "Episode - 239,  Score -  1.0\n",
      "Episode - 240,  Score -  1.0\n",
      "Episode - 241,  Score -  0.0\n",
      "Episode - 242,  Score -  1.0\n",
      "Episode - 243,  Score -  1.0\n",
      "Episode - 244,  Score -  1.0\n",
      "Episode - 245,  Score -  1.0\n",
      "Episode - 246,  Score -  1.0\n",
      "Episode - 247,  Score -  1.0\n",
      "Episode - 248,  Score -  0.0\n",
      "Episode - 249,  Score -  1.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 250\n",
      "Testing Score over time: 0.708\n",
      "Average num of Steps Per Episode: 42.548\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Max Steps - 200\n",
      "Training Score over time: 0.32574\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[3.61987106e-03 2.77069946e-04 2.81625522e-03 1.69543755e-03]\n",
      " [2.03955209e-04 1.18817758e-04 2.11411126e-04 5.31727878e-03]\n",
      " [2.17057140e-03 2.41326790e-02 2.74916134e-04 2.49508893e-04]\n",
      " [5.25663195e-05 1.55798666e-03 4.74325746e-06 7.17709253e-03]\n",
      " [8.90523353e-03 2.39089855e-04 3.24625526e-04 2.57330144e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.15090680e-02 2.00175665e-04 1.50476509e-07 8.49487156e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.29078764e-04 2.87539914e-03 3.97185095e-04 3.62849691e-02]\n",
      " [1.02123301e-03 3.92771358e-02 1.39648471e-02 7.03493280e-04]\n",
      " [1.23754555e-01 1.92974734e-03 5.29094102e-04 4.30365090e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.92509717e-02 2.77638388e-02 5.80415259e-02 1.00999616e-02]\n",
      " [4.54297600e-02 7.88305861e-01 6.75461223e-02 4.41347603e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Episode - 100,  Score -  0.0\n",
      "Episode - 101,  Score -  0.0\n",
      "Episode - 102,  Score -  0.0\n",
      "Episode - 103,  Score -  0.0\n",
      "Episode - 104,  Score -  0.0\n",
      "Episode - 105,  Score -  0.0\n",
      "Episode - 106,  Score -  1.0\n",
      "Episode - 107,  Score -  0.0\n",
      "Episode - 108,  Score -  0.0\n",
      "Episode - 109,  Score -  0.0\n",
      "Episode - 110,  Score -  0.0\n",
      "Episode - 111,  Score -  1.0\n",
      "Episode - 112,  Score -  0.0\n",
      "Episode - 113,  Score -  0.0\n",
      "Episode - 114,  Score -  0.0\n",
      "Episode - 115,  Score -  1.0\n",
      "Episode - 116,  Score -  0.0\n",
      "Episode - 117,  Score -  0.0\n",
      "Episode - 118,  Score -  0.0\n",
      "Episode - 119,  Score -  0.0\n",
      "Episode - 120,  Score -  1.0\n",
      "Episode - 121,  Score -  0.0\n",
      "Episode - 122,  Score -  0.0\n",
      "Episode - 123,  Score -  0.0\n",
      "Episode - 124,  Score -  0.0\n",
      "Episode - 125,  Score -  0.0\n",
      "Episode - 126,  Score -  0.0\n",
      "Episode - 127,  Score -  0.0\n",
      "Episode - 128,  Score -  1.0\n",
      "Episode - 129,  Score -  0.0\n",
      "Episode - 130,  Score -  0.0\n",
      "Episode - 131,  Score -  0.0\n",
      "Episode - 132,  Score -  0.0\n",
      "Episode - 133,  Score -  0.0\n",
      "Episode - 134,  Score -  1.0\n",
      "Episode - 135,  Score -  1.0\n",
      "Episode - 136,  Score -  0.0\n",
      "Episode - 137,  Score -  0.0\n",
      "Episode - 138,  Score -  0.0\n",
      "Episode - 139,  Score -  0.0\n",
      "Episode - 140,  Score -  0.0\n",
      "Episode - 141,  Score -  0.0\n",
      "Episode - 142,  Score -  0.0\n",
      "Episode - 143,  Score -  0.0\n",
      "Episode - 144,  Score -  0.0\n",
      "Episode - 145,  Score -  0.0\n",
      "Episode - 146,  Score -  0.0\n",
      "Episode - 147,  Score -  0.0\n",
      "Episode - 148,  Score -  0.0\n",
      "Episode - 149,  Score -  0.0\n",
      "Episode - 150,  Score -  0.0\n",
      "Episode - 151,  Score -  0.0\n",
      "Episode - 152,  Score -  0.0\n",
      "Episode - 153,  Score -  0.0\n",
      "Episode - 154,  Score -  0.0\n",
      "Episode - 155,  Score -  0.0\n",
      "Episode - 156,  Score -  0.0\n",
      "Episode - 157,  Score -  0.0\n",
      "Episode - 158,  Score -  1.0\n",
      "Episode - 159,  Score -  0.0\n",
      "Episode - 160,  Score -  0.0\n",
      "Episode - 161,  Score -  0.0\n",
      "Episode - 162,  Score -  0.0\n",
      "Episode - 163,  Score -  1.0\n",
      "Episode - 164,  Score -  0.0\n",
      "Episode - 165,  Score -  1.0\n",
      "Episode - 166,  Score -  1.0\n",
      "Episode - 167,  Score -  0.0\n",
      "Episode - 168,  Score -  0.0\n",
      "Episode - 169,  Score -  0.0\n",
      "Episode - 170,  Score -  1.0\n",
      "Episode - 171,  Score -  0.0\n",
      "Episode - 172,  Score -  1.0\n",
      "Episode - 173,  Score -  0.0\n",
      "Episode - 174,  Score -  0.0\n",
      "Episode - 175,  Score -  1.0\n",
      "Episode - 176,  Score -  0.0\n",
      "Episode - 177,  Score -  0.0\n",
      "Episode - 178,  Score -  1.0\n",
      "Episode - 179,  Score -  0.0\n",
      "Episode - 180,  Score -  0.0\n",
      "Episode - 181,  Score -  0.0\n",
      "Episode - 182,  Score -  0.0\n",
      "Episode - 183,  Score -  1.0\n",
      "Episode - 184,  Score -  0.0\n",
      "Episode - 185,  Score -  0.0\n",
      "Episode - 186,  Score -  1.0\n",
      "Episode - 187,  Score -  0.0\n",
      "Episode - 188,  Score -  0.0\n",
      "Episode - 189,  Score -  0.0\n",
      "Episode - 190,  Score -  1.0\n",
      "Episode - 191,  Score -  0.0\n",
      "Episode - 192,  Score -  1.0\n",
      "Episode - 193,  Score -  1.0\n",
      "Episode - 194,  Score -  0.0\n",
      "Episode - 195,  Score -  0.0\n",
      "Episode - 196,  Score -  1.0\n",
      "Episode - 197,  Score -  1.0\n",
      "Episode - 198,  Score -  1.0\n",
      "Episode - 199,  Score -  0.0\n",
      "Episode - 200,  Score -  0.0\n",
      "Episode - 201,  Score -  1.0\n",
      "Episode - 202,  Score -  0.0\n",
      "Episode - 203,  Score -  0.0\n",
      "Episode - 204,  Score -  1.0\n",
      "Episode - 205,  Score -  0.0\n",
      "Episode - 206,  Score -  0.0\n",
      "Episode - 207,  Score -  1.0\n",
      "Episode - 208,  Score -  0.0\n",
      "Episode - 209,  Score -  0.0\n",
      "Episode - 210,  Score -  0.0\n",
      "Episode - 211,  Score -  0.0\n",
      "Episode - 212,  Score -  0.0\n",
      "Episode - 213,  Score -  0.0\n",
      "Episode - 214,  Score -  0.0\n",
      "Episode - 215,  Score -  0.0\n",
      "Episode - 216,  Score -  0.0\n",
      "Episode - 217,  Score -  0.0\n",
      "Episode - 218,  Score -  0.0\n",
      "Episode - 219,  Score -  0.0\n",
      "Episode - 220,  Score -  0.0\n",
      "Episode - 221,  Score -  0.0\n",
      "Episode - 222,  Score -  1.0\n",
      "Episode - 223,  Score -  0.0\n",
      "Episode - 224,  Score -  1.0\n",
      "Episode - 225,  Score -  1.0\n",
      "Episode - 226,  Score -  0.0\n",
      "Episode - 227,  Score -  0.0\n",
      "Episode - 228,  Score -  1.0\n",
      "Episode - 229,  Score -  0.0\n",
      "Episode - 230,  Score -  0.0\n",
      "Episode - 231,  Score -  0.0\n",
      "Episode - 232,  Score -  0.0\n",
      "Episode - 233,  Score -  0.0\n",
      "Episode - 234,  Score -  0.0\n",
      "Episode - 235,  Score -  0.0\n",
      "Episode - 236,  Score -  0.0\n",
      "Episode - 237,  Score -  0.0\n",
      "Episode - 238,  Score -  1.0\n",
      "Episode - 239,  Score -  0.0\n",
      "Episode - 240,  Score -  1.0\n",
      "Episode - 241,  Score -  1.0\n",
      "Episode - 242,  Score -  0.0\n",
      "Episode - 243,  Score -  0.0\n",
      "Episode - 244,  Score -  0.0\n",
      "Episode - 245,  Score -  1.0\n",
      "Episode - 246,  Score -  0.0\n",
      "Episode - 247,  Score -  1.0\n",
      "Episode - 248,  Score -  0.0\n",
      "Episode - 249,  Score -  1.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 250\n",
      "Testing Score over time: 0.244\n",
      "Average num of Steps Per Episode: 33.7\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Max Steps - 400\n",
      "Training Score over time: 0.33374\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.87899859e-02 7.60331267e-04 7.82402791e-04 7.94529877e-04]\n",
      " [9.85217945e-05 4.30664853e-04 1.93842674e-05 5.56708204e-04]\n",
      " [1.96905121e-03 2.60350190e-04 2.46417456e-04 3.48727488e-04]\n",
      " [2.05319708e-05 1.10196378e-04 8.36242975e-06 2.89295685e-04]\n",
      " [7.99568537e-04 1.14984360e-02 8.29905508e-04 4.77618171e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.03843001e-06 3.55580972e-13 9.13892197e-03 1.83322389e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.29398834e-03 1.40698179e-03 5.77791838e-02 4.89522574e-03]\n",
      " [1.93469144e-04 1.11124050e-01 8.23913207e-03 3.64651428e-03]\n",
      " [6.05677738e-02 1.24448940e-02 4.54672261e-03 8.07492798e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.89187540e-02 1.34902037e-02 3.48472882e-01 1.53154025e-02]\n",
      " [7.37074176e-02 7.30445698e-02 1.30061802e-01 7.74292536e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Episode - 100,  Score -  0.0\n",
      "Episode - 101,  Score -  0.0\n",
      "Episode - 102,  Score -  0.0\n",
      "Episode - 103,  Score -  0.0\n",
      "Episode - 104,  Score -  0.0\n",
      "Episode - 105,  Score -  0.0\n",
      "Episode - 106,  Score -  0.0\n",
      "Episode - 107,  Score -  0.0\n",
      "Episode - 108,  Score -  0.0\n",
      "Episode - 109,  Score -  0.0\n",
      "Episode - 110,  Score -  0.0\n",
      "Episode - 111,  Score -  0.0\n",
      "Episode - 112,  Score -  0.0\n",
      "Episode - 113,  Score -  0.0\n",
      "Episode - 114,  Score -  0.0\n",
      "Episode - 115,  Score -  0.0\n",
      "Episode - 116,  Score -  1.0\n",
      "Episode - 117,  Score -  0.0\n",
      "Episode - 118,  Score -  0.0\n",
      "Episode - 119,  Score -  0.0\n",
      "Episode - 120,  Score -  0.0\n",
      "Episode - 121,  Score -  0.0\n",
      "Episode - 122,  Score -  0.0\n",
      "Episode - 123,  Score -  0.0\n",
      "Episode - 124,  Score -  0.0\n",
      "Episode - 125,  Score -  0.0\n",
      "Episode - 126,  Score -  0.0\n",
      "Episode - 127,  Score -  0.0\n",
      "Episode - 128,  Score -  0.0\n",
      "Episode - 129,  Score -  0.0\n",
      "Episode - 130,  Score -  0.0\n",
      "Episode - 131,  Score -  1.0\n",
      "Episode - 132,  Score -  0.0\n",
      "Episode - 133,  Score -  0.0\n",
      "Episode - 134,  Score -  0.0\n",
      "Episode - 135,  Score -  0.0\n",
      "Episode - 136,  Score -  0.0\n",
      "Episode - 137,  Score -  0.0\n",
      "Episode - 138,  Score -  0.0\n",
      "Episode - 139,  Score -  1.0\n",
      "Episode - 140,  Score -  0.0\n",
      "Episode - 141,  Score -  0.0\n",
      "Episode - 142,  Score -  0.0\n",
      "Episode - 143,  Score -  0.0\n",
      "Episode - 144,  Score -  0.0\n",
      "Episode - 145,  Score -  0.0\n",
      "Episode - 146,  Score -  0.0\n",
      "Episode - 147,  Score -  0.0\n",
      "Episode - 148,  Score -  0.0\n",
      "Episode - 149,  Score -  0.0\n",
      "Episode - 150,  Score -  0.0\n",
      "Episode - 151,  Score -  0.0\n",
      "Episode - 152,  Score -  0.0\n",
      "Episode - 153,  Score -  0.0\n",
      "Episode - 154,  Score -  0.0\n",
      "Episode - 155,  Score -  0.0\n",
      "Episode - 156,  Score -  0.0\n",
      "Episode - 157,  Score -  0.0\n",
      "Episode - 158,  Score -  0.0\n",
      "Episode - 159,  Score -  0.0\n",
      "Episode - 160,  Score -  0.0\n",
      "Episode - 161,  Score -  0.0\n",
      "Episode - 162,  Score -  0.0\n",
      "Episode - 163,  Score -  0.0\n",
      "Episode - 164,  Score -  0.0\n",
      "Episode - 165,  Score -  0.0\n",
      "Episode - 166,  Score -  0.0\n",
      "Episode - 167,  Score -  0.0\n",
      "Episode - 168,  Score -  0.0\n",
      "Episode - 169,  Score -  0.0\n",
      "Episode - 170,  Score -  0.0\n",
      "Episode - 171,  Score -  0.0\n",
      "Episode - 172,  Score -  1.0\n",
      "Episode - 173,  Score -  0.0\n",
      "Episode - 174,  Score -  0.0\n",
      "Episode - 175,  Score -  1.0\n",
      "Episode - 176,  Score -  0.0\n",
      "Episode - 177,  Score -  0.0\n",
      "Episode - 178,  Score -  0.0\n",
      "Episode - 179,  Score -  0.0\n",
      "Episode - 180,  Score -  0.0\n",
      "Episode - 181,  Score -  1.0\n",
      "Episode - 182,  Score -  0.0\n",
      "Episode - 183,  Score -  0.0\n",
      "Episode - 184,  Score -  0.0\n",
      "Episode - 185,  Score -  0.0\n",
      "Episode - 186,  Score -  0.0\n",
      "Episode - 187,  Score -  0.0\n",
      "Episode - 188,  Score -  0.0\n",
      "Episode - 189,  Score -  0.0\n",
      "Episode - 190,  Score -  0.0\n",
      "Episode - 191,  Score -  0.0\n",
      "Episode - 192,  Score -  0.0\n",
      "Episode - 193,  Score -  0.0\n",
      "Episode - 194,  Score -  0.0\n",
      "Episode - 195,  Score -  0.0\n",
      "Episode - 196,  Score -  0.0\n",
      "Episode - 197,  Score -  0.0\n",
      "Episode - 198,  Score -  0.0\n",
      "Episode - 199,  Score -  0.0\n",
      "Episode - 200,  Score -  0.0\n",
      "Episode - 201,  Score -  0.0\n",
      "Episode - 202,  Score -  0.0\n",
      "Episode - 203,  Score -  0.0\n",
      "Episode - 204,  Score -  0.0\n",
      "Episode - 205,  Score -  0.0\n",
      "Episode - 206,  Score -  0.0\n",
      "Episode - 207,  Score -  0.0\n",
      "Episode - 208,  Score -  0.0\n",
      "Episode - 209,  Score -  0.0\n",
      "Episode - 210,  Score -  0.0\n",
      "Episode - 211,  Score -  0.0\n",
      "Episode - 212,  Score -  0.0\n",
      "Episode - 213,  Score -  1.0\n",
      "Episode - 214,  Score -  0.0\n",
      "Episode - 215,  Score -  0.0\n",
      "Episode - 216,  Score -  0.0\n",
      "Episode - 217,  Score -  1.0\n",
      "Episode - 218,  Score -  0.0\n",
      "Episode - 219,  Score -  0.0\n",
      "Episode - 220,  Score -  1.0\n",
      "Episode - 221,  Score -  0.0\n",
      "Episode - 222,  Score -  0.0\n",
      "Episode - 223,  Score -  0.0\n",
      "Episode - 224,  Score -  0.0\n",
      "Episode - 225,  Score -  0.0\n",
      "Episode - 226,  Score -  0.0\n",
      "Episode - 227,  Score -  0.0\n",
      "Episode - 228,  Score -  0.0\n",
      "Episode - 229,  Score -  0.0\n",
      "Episode - 230,  Score -  0.0\n",
      "Episode - 231,  Score -  1.0\n",
      "Episode - 232,  Score -  0.0\n",
      "Episode - 233,  Score -  0.0\n",
      "Episode - 234,  Score -  0.0\n",
      "Episode - 235,  Score -  0.0\n",
      "Episode - 236,  Score -  0.0\n",
      "Episode - 237,  Score -  0.0\n",
      "Episode - 238,  Score -  0.0\n",
      "Episode - 239,  Score -  0.0\n",
      "Episode - 240,  Score -  0.0\n",
      "Episode - 241,  Score -  0.0\n",
      "Episode - 242,  Score -  0.0\n",
      "Episode - 243,  Score -  0.0\n",
      "Episode - 244,  Score -  0.0\n",
      "Episode - 245,  Score -  0.0\n",
      "Episode - 246,  Score -  0.0\n",
      "Episode - 247,  Score -  0.0\n",
      "Episode - 248,  Score -  0.0\n",
      "Episode - 249,  Score -  0.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 250\n",
      "Testing Score over time: 0.056\n",
      "Average num of Steps Per Episode: 5.796\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Max Steps - 500\n",
      "Training Score over time: 0.33188\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[2.26356835e-03 2.12301303e-03 3.75850292e-03 5.61757530e-04]\n",
      " [3.00641232e-06 6.79837676e-06 3.60909837e-04 1.63189759e-03]\n",
      " [5.64772296e-05 5.39795025e-05 7.71187598e-04 1.91723385e-03]\n",
      " [4.42615320e-05 5.36748044e-04 2.38016794e-06 1.46960455e-03]\n",
      " [1.57097292e-02 8.07475318e-04 1.10515277e-03 1.14278302e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.98706413e-04 3.16412522e-07 2.04502186e-05 6.99751977e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.67051702e-03 7.91302492e-04 7.96701398e-02 1.76255874e-02]\n",
      " [2.52108408e-03 6.48803597e-02 1.93128948e-05 1.51005852e-02]\n",
      " [3.57981963e-01 1.30185732e-03 9.18648286e-04 5.57309181e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.86701129e-02 5.98684612e-03 1.17723586e-01 6.84407513e-03]\n",
      " [7.53760075e-02 8.83255869e-01 1.42756248e-02 2.56617018e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Episode - 100,  Score -  1.0\n",
      "Episode - 101,  Score -  1.0\n",
      "Episode - 102,  Score -  0.0\n",
      "Episode - 103,  Score -  0.0\n",
      "Episode - 104,  Score -  0.0\n",
      "Episode - 105,  Score -  0.0\n",
      "Episode - 106,  Score -  0.0\n",
      "Episode - 107,  Score -  0.0\n",
      "Episode - 108,  Score -  0.0\n",
      "Episode - 109,  Score -  0.0\n",
      "Episode - 110,  Score -  0.0\n",
      "Episode - 111,  Score -  0.0\n",
      "Episode - 112,  Score -  0.0\n",
      "Episode - 113,  Score -  0.0\n",
      "Episode - 114,  Score -  1.0\n",
      "Episode - 115,  Score -  1.0\n",
      "Episode - 116,  Score -  0.0\n",
      "Episode - 117,  Score -  0.0\n",
      "Episode - 118,  Score -  0.0\n",
      "Episode - 119,  Score -  0.0\n",
      "Episode - 120,  Score -  1.0\n",
      "Episode - 121,  Score -  0.0\n",
      "Episode - 122,  Score -  0.0\n",
      "Episode - 123,  Score -  1.0\n",
      "Episode - 124,  Score -  1.0\n",
      "Episode - 125,  Score -  0.0\n",
      "Episode - 126,  Score -  0.0\n",
      "Episode - 127,  Score -  0.0\n",
      "Episode - 128,  Score -  0.0\n",
      "Episode - 129,  Score -  1.0\n",
      "Episode - 130,  Score -  1.0\n",
      "Episode - 131,  Score -  0.0\n",
      "Episode - 132,  Score -  0.0\n",
      "Episode - 133,  Score -  0.0\n",
      "Episode - 134,  Score -  0.0\n",
      "Episode - 135,  Score -  0.0\n",
      "Episode - 136,  Score -  1.0\n",
      "Episode - 137,  Score -  1.0\n",
      "Episode - 138,  Score -  1.0\n",
      "Episode - 139,  Score -  1.0\n",
      "Episode - 140,  Score -  1.0\n",
      "Episode - 141,  Score -  0.0\n",
      "Episode - 142,  Score -  1.0\n",
      "Episode - 143,  Score -  0.0\n",
      "Episode - 144,  Score -  0.0\n",
      "Episode - 145,  Score -  0.0\n",
      "Episode - 146,  Score -  0.0\n",
      "Episode - 147,  Score -  1.0\n",
      "Episode - 148,  Score -  0.0\n",
      "Episode - 149,  Score -  0.0\n",
      "Episode - 150,  Score -  1.0\n",
      "Episode - 151,  Score -  1.0\n",
      "Episode - 152,  Score -  0.0\n",
      "Episode - 153,  Score -  0.0\n",
      "Episode - 154,  Score -  1.0\n",
      "Episode - 155,  Score -  1.0\n",
      "Episode - 156,  Score -  0.0\n",
      "Episode - 157,  Score -  0.0\n",
      "Episode - 158,  Score -  0.0\n",
      "Episode - 159,  Score -  0.0\n",
      "Episode - 160,  Score -  0.0\n",
      "Episode - 161,  Score -  0.0\n",
      "Episode - 162,  Score -  0.0\n",
      "Episode - 163,  Score -  1.0\n",
      "Episode - 164,  Score -  0.0\n",
      "Episode - 165,  Score -  1.0\n",
      "Episode - 166,  Score -  1.0\n",
      "Episode - 167,  Score -  0.0\n",
      "Episode - 168,  Score -  0.0\n",
      "Episode - 169,  Score -  0.0\n",
      "Episode - 170,  Score -  0.0\n",
      "Episode - 171,  Score -  0.0\n",
      "Episode - 172,  Score -  0.0\n",
      "Episode - 173,  Score -  0.0\n",
      "Episode - 174,  Score -  0.0\n",
      "Episode - 175,  Score -  0.0\n",
      "Episode - 176,  Score -  0.0\n",
      "Episode - 177,  Score -  1.0\n",
      "Episode - 178,  Score -  1.0\n",
      "Episode - 179,  Score -  0.0\n",
      "Episode - 180,  Score -  0.0\n",
      "Episode - 181,  Score -  1.0\n",
      "Episode - 182,  Score -  1.0\n",
      "Episode - 183,  Score -  1.0\n",
      "Episode - 184,  Score -  0.0\n",
      "Episode - 185,  Score -  0.0\n",
      "Episode - 186,  Score -  1.0\n",
      "Episode - 187,  Score -  1.0\n",
      "Episode - 188,  Score -  0.0\n",
      "Episode - 189,  Score -  0.0\n",
      "Episode - 190,  Score -  1.0\n",
      "Episode - 191,  Score -  0.0\n",
      "Episode - 192,  Score -  0.0\n",
      "Episode - 193,  Score -  0.0\n",
      "Episode - 194,  Score -  1.0\n",
      "Episode - 195,  Score -  0.0\n",
      "Episode - 196,  Score -  1.0\n",
      "Episode - 197,  Score -  1.0\n",
      "Episode - 198,  Score -  0.0\n",
      "Episode - 199,  Score -  0.0\n",
      "Episode - 200,  Score -  1.0\n",
      "Episode - 201,  Score -  0.0\n",
      "Episode - 202,  Score -  0.0\n",
      "Episode - 203,  Score -  0.0\n",
      "Episode - 204,  Score -  1.0\n",
      "Episode - 205,  Score -  0.0\n",
      "Episode - 206,  Score -  0.0\n",
      "Episode - 207,  Score -  1.0\n",
      "Episode - 208,  Score -  0.0\n",
      "Episode - 209,  Score -  0.0\n",
      "Episode - 210,  Score -  1.0\n",
      "Episode - 211,  Score -  0.0\n",
      "Episode - 212,  Score -  0.0\n",
      "Episode - 213,  Score -  0.0\n",
      "Episode - 214,  Score -  0.0\n",
      "Episode - 215,  Score -  0.0\n",
      "Episode - 216,  Score -  0.0\n",
      "Episode - 217,  Score -  0.0\n",
      "Episode - 218,  Score -  1.0\n",
      "Episode - 219,  Score -  0.0\n",
      "Episode - 220,  Score -  0.0\n",
      "Episode - 221,  Score -  0.0\n",
      "Episode - 222,  Score -  0.0\n",
      "Episode - 223,  Score -  0.0\n",
      "Episode - 224,  Score -  1.0\n",
      "Episode - 225,  Score -  1.0\n",
      "Episode - 226,  Score -  0.0\n",
      "Episode - 227,  Score -  1.0\n",
      "Episode - 228,  Score -  1.0\n",
      "Episode - 229,  Score -  0.0\n",
      "Episode - 230,  Score -  0.0\n",
      "Episode - 231,  Score -  1.0\n",
      "Episode - 232,  Score -  1.0\n",
      "Episode - 233,  Score -  0.0\n",
      "Episode - 234,  Score -  0.0\n",
      "Episode - 235,  Score -  0.0\n",
      "Episode - 236,  Score -  0.0\n",
      "Episode - 237,  Score -  0.0\n",
      "Episode - 238,  Score -  0.0\n",
      "Episode - 239,  Score -  0.0\n",
      "Episode - 240,  Score -  0.0\n",
      "Episode - 241,  Score -  0.0\n",
      "Episode - 242,  Score -  0.0\n",
      "Episode - 243,  Score -  0.0\n",
      "Episode - 244,  Score -  0.0\n",
      "Episode - 245,  Score -  0.0\n",
      "Episode - 246,  Score -  1.0\n",
      "Episode - 247,  Score -  0.0\n",
      "Episode - 248,  Score -  0.0\n",
      "Episode - 249,  Score -  1.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 250\n",
      "Testing Score over time: 0.252\n",
      "Average num of Steps Per Episode: 39.248\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [50, 100, 200, 400, 500]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 250     # Total test episodes\n",
    "    max_steps = param                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7           # Learning rate\n",
    "    gamma = 0.8                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1.0                 # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = 0.01             # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Max Steps - \" + str(max_steps))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Learning Rate value - \" + str(learning_rate))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I revalidated the Testing score with more number of test episodes. \n",
    "\n",
    "### So by tuning the Number of Episodes and Max Steps, I am able to get 0.75 testing score as oppose to 0.32 baseline score. \n",
    "### An improvement of 135%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Learning Rate (Using the best values for Episodes and Max Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.0\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.1\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 18.69\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.29904\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0.02161031 0.00394639 0.00443882 0.00317737]\n",
      " [0.00227744 0.00310863 0.00307621 0.005797  ]\n",
      " [0.01489987 0.00789961 0.00722541 0.00800725]\n",
      " [0.00401939 0.00289612 0.0021057  0.00288168]\n",
      " [0.03825178 0.00438364 0.0047531  0.00570722]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.03788342 0.00331641 0.00311637 0.00217041]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.00792057 0.00776577 0.00626519 0.08317052]\n",
      " [0.02272368 0.1678525  0.02521182 0.02389456]\n",
      " [0.28693197 0.0735286  0.03187176 0.02432828]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.09408471 0.03304093 0.28805761 0.04154173]\n",
      " [0.14996848 0.15935339 0.57037839 0.19558737]\n",
      " [0.         0.         0.         0.        ]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  1.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Learning Rate value - 0.25\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.57\n",
      "Average num of Steps Per Episode: 43.18\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.30568\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[4.44247827e-03 1.27337292e-02 4.46012833e-03 3.22270118e-03]\n",
      " [1.37055485e-03 1.60483809e-03 1.87961681e-03 1.64374922e-02]\n",
      " [3.33434223e-03 3.34905668e-03 7.08425588e-02 3.19753228e-03]\n",
      " [1.74514730e-04 1.96209260e-03 4.69113096e-04 2.57740105e-02]\n",
      " [5.09569857e-02 3.93283604e-03 4.04303982e-03 3.67087894e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.81016466e-03 8.72960907e-04 2.62209864e-01 2.66365223e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.07613996e-02 8.86389369e-03 6.27820174e-03 1.32634371e-01]\n",
      " [1.09325107e-02 2.03859242e-01 8.52936986e-03 3.08016034e-02]\n",
      " [6.08878213e-01 4.28547913e-03 1.34251410e-02 4.05479511e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.58267972e-02 3.09347730e-02 3.86436039e-01 3.72460522e-02]\n",
      " [1.07926483e-01 1.06757967e-01 8.38378118e-01 9.33174815e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.4\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.4\n",
      "Average num of Steps Per Episode: 23.7\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.30614\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.79767331e-02 6.87037233e-03 3.11314344e-03 2.86645328e-03]\n",
      " [3.20132558e-04 3.73689070e-04 4.92811515e-04 1.43050831e-02]\n",
      " [2.77683588e-02 1.55045999e-03 2.28460672e-03 2.25984332e-03]\n",
      " [2.46117011e-04 1.87735241e-04 1.58926049e-03 2.27555146e-03]\n",
      " [3.63347154e-02 3.89900801e-03 9.17655407e-04 1.45448150e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [9.12514683e-02 2.00275454e-05 3.71644777e-04 1.13220173e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.76150270e-03 1.82316615e-02 2.19082522e-02 3.50798222e-02]\n",
      " [3.82830582e-03 1.27263152e-01 2.83809149e-03 7.65890519e-03]\n",
      " [3.17309384e-01 6.00827088e-03 4.99222217e-03 1.03574547e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.03497467e-02 4.58710760e-02 1.83672124e-01 1.13345736e-02]\n",
      " [9.70891684e-02 5.91420333e-01 1.48547889e-01 6.41684824e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  1.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Learning Rate value - 0.5\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.74\n",
      "Average num of Steps Per Episode: 43.0\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.32304\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[3.58139197e-03 3.35205378e-02 3.92145810e-03 5.00549037e-04]\n",
      " [3.53062381e-05 6.38270254e-04 1.13738192e-04 1.45342245e-02]\n",
      " [6.19405010e-03 1.72453559e-04 1.55167961e-04 1.15301409e-04]\n",
      " [5.06904849e-05 1.25523293e-05 3.28698525e-05 7.96089112e-05]\n",
      " [4.85306918e-02 1.56140134e-03 1.09659112e-03 4.23924826e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.69281299e-02 1.25436012e-07 3.10541160e-03 5.04785467e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.26761763e-03 2.61572990e-03 2.75113505e-03 8.89502954e-02]\n",
      " [1.38746834e-02 1.90358550e-01 9.95923184e-04 8.85551469e-04]\n",
      " [4.98730081e-01 2.60905202e-02 1.04099721e-03 2.02509029e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.04160107e-02 2.42969996e-02 4.35015013e-01 7.47125395e-02]\n",
      " [8.26392036e-02 7.25494888e-01 1.96096111e-01 5.45805214e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.6\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.55\n",
      "Average num of Steps Per Episode: 28.68\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.32236\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[5.24969946e-04 5.70826394e-04 7.40456613e-03 5.38501382e-04]\n",
      " [3.86826147e-04 1.60397526e-05 6.13035132e-04 3.63448659e-03]\n",
      " [4.12297490e-03 1.74812249e-03 5.74169907e-04 2.30424556e-05]\n",
      " [8.70594905e-06 2.82340232e-03 4.84378023e-06 1.33419036e-05]\n",
      " [6.62504261e-02 3.59181685e-06 6.61831484e-04 9.48834685e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.33946494e-02 6.62394656e-09 3.60587454e-04 4.49439185e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.46573835e-03 6.31512621e-04 3.28928885e-03 8.25084515e-02]\n",
      " [9.30140261e-03 1.20067627e-01 8.14898604e-03 3.40081066e-03]\n",
      " [1.26341106e-01 1.27121867e-03 1.32888409e-02 6.46114798e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.48661952e-04 4.46292734e-04 1.57003481e-01 1.03577244e-03]\n",
      " [5.03540385e-02 1.56634408e-01 5.81078662e-02 7.61434173e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Learning Rate value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.48\n",
      "Average num of Steps Per Episode: 29.75\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.33594\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.93942076e-03 1.19224457e-03 1.21318699e-03 7.39651557e-04]\n",
      " [1.93890210e-05 3.24298429e-06 5.27752067e-06 1.00553006e-03]\n",
      " [2.57973497e-05 2.62439612e-04 2.79307708e-05 2.19077587e-05]\n",
      " [1.35771168e-06 4.25110499e-06 1.21891491e-05 8.40164856e-04]\n",
      " [1.01126931e-01 1.46879207e-04 4.79204168e-08 5.38101431e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.43186810e-05 1.79944867e-07 1.94207402e-06 1.23249005e-08]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.41105490e-04 1.87921216e-03 3.68780998e-04 7.47547547e-02]\n",
      " [1.72980518e-04 3.92000340e-03 2.28786072e-03 3.95167594e-02]\n",
      " [6.29450730e-01 4.80592670e-04 1.94832143e-04 2.93303985e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.16190746e-04 1.33013003e-02 3.12445329e-01 5.15125660e-03]\n",
      " [9.28205359e-02 8.86832207e-01 5.72925727e-03 4.42654811e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Learning Rate value - 0.8\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.23\n",
      "Average num of Steps Per Episode: 27.98\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.36378\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.34218231e-05 9.46902547e-03 3.19522244e-04 1.40062015e-05]\n",
      " [4.60842573e-07 1.54790415e-07 6.47001380e-07 1.74025079e-03]\n",
      " [6.37726641e-07 4.08911600e-07 2.06447774e-02 1.30272610e-06]\n",
      " [3.92234531e-05 4.45275359e-07 3.03706215e-07 1.95269795e-02]\n",
      " [4.18596361e-02 1.12526126e-03 3.07139702e-08 1.27445096e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.90018439e-09 2.70350674e-07 2.86032403e-03 2.37302023e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.46130347e-06 1.43080381e-03 1.01004167e-03 8.13338329e-02]\n",
      " [1.40757302e-04 5.34668415e-01 4.23531230e-03 1.26147325e-04]\n",
      " [1.15229829e-05 2.78448498e-01 2.87017753e-06 1.71249587e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.38610671e-04 3.72372698e-08 7.79361998e-01 2.11129297e-05]\n",
      " [3.15992892e-02 6.61095644e-01 3.11960752e-02 1.15342234e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Learning Rate value - 0.9\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.4\n",
      "Average num of Steps Per Episode: 22.75\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.1, 0.25, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 100                # Max steps per episode\n",
    "\n",
    "    learning_rate = param           # Learning rate\n",
    "    gamma = 0.8                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1.0                 # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = 0.01             # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Learning Rate value - \" + str(learning_rate))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest Testing score is with 0.74 which is equal to what I got earlier with the base 0.7 value of Learning rate. \n",
    "Lets use Learning rate of 0.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning for Gamma using the best values from previous iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 6e-05\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.        0.        0.       ]\n",
      " [0.        0.1328125 0.03125   0.       ]\n",
      " [0.        0.        0.        0.       ]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Gamma value - 0\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 16.8\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.07606\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[2.99111526e-08 4.38629032e-08 7.30999371e-08 1.61466706e-10]\n",
      " [1.89306532e-11 1.89367574e-08 3.63959504e-08 4.17856562e-08]\n",
      " [1.79830506e-09 1.79098129e-09 1.22793493e-04 1.24402612e-09]\n",
      " [7.93601250e-11 1.77773559e-09 2.78749924e-12 9.55780756e-07]\n",
      " [2.79487568e-07 1.99355388e-07 2.20255971e-09 1.70287004e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.55059959e-03 1.04807568e-09 8.41899303e-08 1.00801738e-11]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.71349894e-08 2.49925882e-04 3.83656713e-08 5.50680959e-08]\n",
      " [2.39183122e-06 5.42149569e-04 1.66399405e-03 1.55693992e-06]\n",
      " [6.01921620e-06 5.07203481e-03 8.85584921e-06 7.74604184e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.81632641e-06 6.97638111e-06 4.51623445e-06 5.78008160e-04]\n",
      " [4.37714700e-04 1.40926073e-03 1.09342652e-03 2.59188523e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Gamma value - 0.15\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.09\n",
      "Average num of Steps Per Episode: 11.89\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.08076\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[2.60753784e-08 9.21179167e-06 2.41974199e-06 2.55183189e-08]\n",
      " [7.58910294e-08 3.52939653e-05 1.22742320e-06 1.13992007e-07]\n",
      " [2.14337155e-06 2.41928333e-04 2.56104649e-07 3.38782443e-07]\n",
      " [1.88286085e-07 7.86266103e-05 8.77086132e-10 1.86950261e-08]\n",
      " [8.71839779e-08 5.54229543e-08 9.79719149e-06 1.15345554e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.53833749e-06 1.58416309e-09 1.23546851e-03 4.96139813e-08]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.03588891e-06 1.38653404e-06 1.39689529e-06 9.22785363e-04]\n",
      " [7.05138637e-05 6.52354784e-05 5.31258724e-03 2.76930334e-05]\n",
      " [1.12404770e-02 1.50480882e-04 9.25034696e-05 2.71427862e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.33966619e-05 6.05865127e-03 8.16168020e-05 5.26644812e-02]\n",
      " [1.73497617e-03 1.56771514e-01 1.62062345e-03 1.76555857e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Gamma value - 0.3\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.06\n",
      "Average num of Steps Per Episode: 5.46\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.11472\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.28043592e-05 5.48935375e-04 2.15037783e-04 3.75736159e-06]\n",
      " [4.56825794e-07 5.45737570e-06 3.03052312e-07 8.06364740e-04]\n",
      " [1.50586764e-03 3.89409587e-06 5.48810812e-06 5.43074846e-06]\n",
      " [9.64537393e-08 6.19302011e-07 5.15643545e-07 1.91913537e-06]\n",
      " [1.22359638e-03 4.71247051e-07 1.65689638e-05 1.27139529e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.56403819e-05 1.54368222e-02 1.77340803e-04 6.84729900e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.83557559e-05 3.87209532e-03 4.40619880e-06 4.46269750e-06]\n",
      " [4.41998368e-05 1.02100845e-02 2.33766092e-03 1.31443792e-03]\n",
      " [3.95454112e-02 2.15694003e-03 1.34484984e-04 1.64750759e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.00338241e-04 1.34282750e-04 9.27276069e-02 2.41506174e-03]\n",
      " [1.17593862e-02 6.83990899e-01 1.46041776e-02 1.63818858e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Gamma value - 0.45\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.19\n",
      "Average num of Steps Per Episode: 13.37\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.12594\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[2.64499019e-05 2.87096827e-05 8.09093143e-05 3.06552062e-05]\n",
      " [1.34630354e-05 5.33683563e-05 6.34205500e-05 9.17519310e-06]\n",
      " [2.73740595e-04 3.05463104e-04 1.39382411e-06 3.83864664e-05]\n",
      " [3.21644430e-07 3.88959444e-07 2.45434316e-05 1.31472475e-04]\n",
      " [3.46730159e-05 1.39579174e-06 3.23242937e-07 3.85990754e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.72521850e-04 6.83747823e-06 1.61848111e-03 1.51916724e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.31756312e-05 8.81984326e-05 2.06872733e-05 1.13594549e-03]\n",
      " [2.96077898e-04 7.52273243e-04 2.24032956e-02 2.95147855e-04]\n",
      " [2.89896131e-01 5.04517485e-04 3.32849074e-04 4.07621954e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.92597192e-03 1.09259616e-01 8.96285438e-03 9.24142943e-03]\n",
      " [2.88574032e-02 6.36109190e-01 3.91099817e-03 2.53497999e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Gamma value - 0.5\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.13\n",
      "Average num of Steps Per Episode: 9.5\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.15384\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.43048978e-05 1.16209236e-04 5.20745614e-05 2.27134600e-05]\n",
      " [6.38420589e-06 9.09663374e-06 9.47676609e-06 1.30041615e-04]\n",
      " [7.29559969e-04 4.56741843e-05 1.56119092e-05 3.29016609e-05]\n",
      " [3.61628873e-05 4.41545293e-06 7.55072218e-08 5.81583093e-06]\n",
      " [1.56913050e-04 3.85031856e-05 1.21510290e-05 2.00145174e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.36888305e-04 6.47030063e-06 1.04521168e-02 1.30167918e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.88394055e-04 1.91469952e-04 5.42755589e-03 1.97514054e-04]\n",
      " [5.23966976e-04 1.24652431e-02 4.99381795e-04 1.77498777e-04]\n",
      " [1.80063641e-02 2.85663954e-04 1.39285224e-03 1.49858934e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.52583902e-04 1.01524127e-03 2.14384951e-02 2.86814751e-03]\n",
      " [5.72709879e-03 5.69091201e-01 5.13639912e-03 7.08269481e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Gamma value - 0.6\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.27\n",
      "Average num of Steps Per Episode: 17.54\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.22606\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[6.33273474e-04 5.62751699e-03 6.32011897e-04 5.67404514e-04]\n",
      " [3.84926815e-04 5.54923210e-03 6.88207080e-04 7.40060721e-04]\n",
      " [1.71085953e-03 1.45007661e-03 1.73675239e-02 1.66797542e-03]\n",
      " [5.16939094e-05 3.33002626e-05 1.75205729e-05 1.52038832e-03]\n",
      " [1.03386988e-02 4.17327137e-05 9.36547001e-04 3.03413940e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.44147565e-03 9.08978219e-05 2.30643229e-02 4.99268040e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.18365090e-03 1.12685453e-03 1.17418262e-03 2.78937658e-02]\n",
      " [6.98159754e-03 1.32988545e-01 3.52336267e-03 8.25867593e-03]\n",
      " [9.37047516e-03 7.58001491e-03 4.18992308e-01 8.11121149e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [9.44568337e-03 5.65926535e-03 4.08014145e-01 3.32582081e-03]\n",
      " [5.49895608e-02 6.12153648e-02 4.34454107e-01 5.23249641e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Gamma value - 0.7\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.12\n",
      "Average num of Steps Per Episode: 13.81\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.30042\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[4.95780373e-03 4.87013619e-03 7.35094514e-03 4.84083592e-03]\n",
      " [1.04929327e-03 4.16318954e-04 6.32111063e-04 8.65002349e-03]\n",
      " [1.21218277e-02 6.67793628e-03 1.24061014e-03 1.12499763e-03]\n",
      " [4.48459752e-04 1.48988714e-04 5.20428660e-04 5.52361135e-04]\n",
      " [3.57030203e-02 2.65730595e-03 5.33513350e-04 4.84593754e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [9.03982516e-02 1.42352856e-04 4.12253906e-04 7.28020322e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.78659539e-03 3.15091046e-03 5.18980127e-03 8.14904350e-02]\n",
      " [1.68848991e-02 1.61200807e-01 1.43856365e-02 1.49341525e-02]\n",
      " [2.68892672e-01 1.56585673e-02 1.31837272e-04 1.75402930e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.19217021e-02 4.27714462e-02 2.47881959e-01 1.98156539e-02]\n",
      " [6.97489064e-02 7.30704243e-01 1.14323807e-01 1.17296068e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Gamma value - 0.8\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.51\n",
      "Average num of Steps Per Episode: 28.97\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.42296\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.51477613e-02 1.50879316e-02 6.73956254e-02 1.46582956e-02]\n",
      " [8.85511475e-03 7.28801224e-03 7.53198427e-03 2.33028162e-02]\n",
      " [8.28450031e-03 7.60705552e-03 9.05878284e-03 1.02466631e-02]\n",
      " [4.73835149e-03 1.51079412e-03 1.42740374e-03 7.73036108e-03]\n",
      " [7.74951275e-02 2.39764158e-02 2.49539266e-02 9.29758123e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.48981319e-03 4.06825782e-04 4.02141253e-02 1.66236620e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.30730036e-02 2.83684924e-02 1.30573106e-02 2.27243849e-01]\n",
      " [5.91856682e-02 5.39307608e-01 3.09165093e-02 3.24934580e-02]\n",
      " [4.03219589e-01 2.52953014e-02 1.74017339e-02 2.13170158e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.50697645e-01 4.18933375e-02 5.17303044e-01 5.03983473e-02]\n",
      " [3.98867811e-01 7.65988245e-01 2.40460805e-01 5.37432218e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Gamma value - 0.9\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.49\n",
      "Average num of Steps Per Episode: 64.08\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.02024\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0.94505183 0.97265487 0.95577487 0.97877574]\n",
      " [0.85498729 0.66465117 0.23704417 0.97877574]\n",
      " [0.39327996 0.80174752 0.63601182 0.97877574]\n",
      " [0.96035582 0.93171919 0.88354617 0.97877574]\n",
      " [0.94205318 0.78752381 0.43146936 0.41759322]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.01244931 0.00961964 0.01221294 0.80302806]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.81012373 0.74236775 0.20389573 0.89515782]\n",
      " [0.61960481 0.90686773 0.32229476 0.10097072]\n",
      " [0.94684421 0.12509742 0.29227427 0.30210044]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.62975938 0.79680491 0.95430454 0.19902122]\n",
      " [0.85880488 0.99830629 0.8659565  0.87000396]\n",
      " [0.         0.         0.         0.        ]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Gamma value - 1\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 99.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0, 0.15, 0.3, 0.45, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 100                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.5          # Learning rate\n",
    "    gamma = param                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1.0                 # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = 0.01             # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Gamma value - \" + str(gamma))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.0\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Episode - 100,  Score -  0.0\n",
      "Episode - 101,  Score -  0.0\n",
      "Episode - 102,  Score -  0.0\n",
      "Episode - 103,  Score -  0.0\n",
      "Episode - 104,  Score -  0.0\n",
      "Episode - 105,  Score -  0.0\n",
      "Episode - 106,  Score -  0.0\n",
      "Episode - 107,  Score -  0.0\n",
      "Episode - 108,  Score -  0.0\n",
      "Episode - 109,  Score -  0.0\n",
      "Episode - 110,  Score -  0.0\n",
      "Episode - 111,  Score -  0.0\n",
      "Episode - 112,  Score -  0.0\n",
      "Episode - 113,  Score -  0.0\n",
      "Episode - 114,  Score -  0.0\n",
      "Episode - 115,  Score -  0.0\n",
      "Episode - 116,  Score -  0.0\n",
      "Episode - 117,  Score -  0.0\n",
      "Episode - 118,  Score -  0.0\n",
      "Episode - 119,  Score -  0.0\n",
      "Episode - 120,  Score -  0.0\n",
      "Episode - 121,  Score -  0.0\n",
      "Episode - 122,  Score -  0.0\n",
      "Episode - 123,  Score -  0.0\n",
      "Episode - 124,  Score -  0.0\n",
      "Episode - 125,  Score -  0.0\n",
      "Episode - 126,  Score -  0.0\n",
      "Episode - 127,  Score -  0.0\n",
      "Episode - 128,  Score -  0.0\n",
      "Episode - 129,  Score -  0.0\n",
      "Episode - 130,  Score -  0.0\n",
      "Episode - 131,  Score -  0.0\n",
      "Episode - 132,  Score -  0.0\n",
      "Episode - 133,  Score -  0.0\n",
      "Episode - 134,  Score -  0.0\n",
      "Episode - 135,  Score -  0.0\n",
      "Episode - 136,  Score -  0.0\n",
      "Episode - 137,  Score -  0.0\n",
      "Episode - 138,  Score -  0.0\n",
      "Episode - 139,  Score -  0.0\n",
      "Episode - 140,  Score -  0.0\n",
      "Episode - 141,  Score -  0.0\n",
      "Episode - 142,  Score -  0.0\n",
      "Episode - 143,  Score -  0.0\n",
      "Episode - 144,  Score -  0.0\n",
      "Episode - 145,  Score -  0.0\n",
      "Episode - 146,  Score -  0.0\n",
      "Episode - 147,  Score -  0.0\n",
      "Episode - 148,  Score -  0.0\n",
      "Episode - 149,  Score -  0.0\n",
      "Episode - 150,  Score -  0.0\n",
      "Episode - 151,  Score -  0.0\n",
      "Episode - 152,  Score -  0.0\n",
      "Episode - 153,  Score -  0.0\n",
      "Episode - 154,  Score -  0.0\n",
      "Episode - 155,  Score -  0.0\n",
      "Episode - 156,  Score -  0.0\n",
      "Episode - 157,  Score -  0.0\n",
      "Episode - 158,  Score -  0.0\n",
      "Episode - 159,  Score -  0.0\n",
      "Episode - 160,  Score -  0.0\n",
      "Episode - 161,  Score -  0.0\n",
      "Episode - 162,  Score -  0.0\n",
      "Episode - 163,  Score -  0.0\n",
      "Episode - 164,  Score -  0.0\n",
      "Episode - 165,  Score -  0.0\n",
      "Episode - 166,  Score -  0.0\n",
      "Episode - 167,  Score -  0.0\n",
      "Episode - 168,  Score -  0.0\n",
      "Episode - 169,  Score -  0.0\n",
      "Episode - 170,  Score -  0.0\n",
      "Episode - 171,  Score -  0.0\n",
      "Episode - 172,  Score -  0.0\n",
      "Episode - 173,  Score -  0.0\n",
      "Episode - 174,  Score -  0.0\n",
      "Episode - 175,  Score -  0.0\n",
      "Episode - 176,  Score -  0.0\n",
      "Episode - 177,  Score -  0.0\n",
      "Episode - 178,  Score -  0.0\n",
      "Episode - 179,  Score -  0.0\n",
      "Episode - 180,  Score -  0.0\n",
      "Episode - 181,  Score -  0.0\n",
      "Episode - 182,  Score -  0.0\n",
      "Episode - 183,  Score -  0.0\n",
      "Episode - 184,  Score -  0.0\n",
      "Episode - 185,  Score -  0.0\n",
      "Episode - 186,  Score -  0.0\n",
      "Episode - 187,  Score -  0.0\n",
      "Episode - 188,  Score -  0.0\n",
      "Episode - 189,  Score -  0.0\n",
      "Episode - 190,  Score -  0.0\n",
      "Episode - 191,  Score -  0.0\n",
      "Episode - 192,  Score -  0.0\n",
      "Episode - 193,  Score -  0.0\n",
      "Episode - 194,  Score -  0.0\n",
      "Episode - 195,  Score -  0.0\n",
      "Episode - 196,  Score -  0.0\n",
      "Episode - 197,  Score -  0.0\n",
      "Episode - 198,  Score -  0.0\n",
      "Episode - 199,  Score -  0.0\n",
      "Episode - 200,  Score -  0.0\n",
      "Episode - 201,  Score -  0.0\n",
      "Episode - 202,  Score -  0.0\n",
      "Episode - 203,  Score -  0.0\n",
      "Episode - 204,  Score -  0.0\n",
      "Episode - 205,  Score -  0.0\n",
      "Episode - 206,  Score -  0.0\n",
      "Episode - 207,  Score -  0.0\n",
      "Episode - 208,  Score -  0.0\n",
      "Episode - 209,  Score -  0.0\n",
      "Episode - 210,  Score -  0.0\n",
      "Episode - 211,  Score -  0.0\n",
      "Episode - 212,  Score -  0.0\n",
      "Episode - 213,  Score -  0.0\n",
      "Episode - 214,  Score -  0.0\n",
      "Episode - 215,  Score -  0.0\n",
      "Episode - 216,  Score -  0.0\n",
      "Episode - 217,  Score -  0.0\n",
      "Episode - 218,  Score -  0.0\n",
      "Episode - 219,  Score -  0.0\n",
      "Episode - 220,  Score -  0.0\n",
      "Episode - 221,  Score -  0.0\n",
      "Episode - 222,  Score -  0.0\n",
      "Episode - 223,  Score -  0.0\n",
      "Episode - 224,  Score -  0.0\n",
      "Episode - 225,  Score -  0.0\n",
      "Episode - 226,  Score -  0.0\n",
      "Episode - 227,  Score -  0.0\n",
      "Episode - 228,  Score -  0.0\n",
      "Episode - 229,  Score -  0.0\n",
      "Episode - 230,  Score -  0.0\n",
      "Episode - 231,  Score -  0.0\n",
      "Episode - 232,  Score -  0.0\n",
      "Episode - 233,  Score -  0.0\n",
      "Episode - 234,  Score -  0.0\n",
      "Episode - 235,  Score -  0.0\n",
      "Episode - 236,  Score -  0.0\n",
      "Episode - 237,  Score -  0.0\n",
      "Episode - 238,  Score -  0.0\n",
      "Episode - 239,  Score -  0.0\n",
      "Episode - 240,  Score -  0.0\n",
      "Episode - 241,  Score -  0.0\n",
      "Episode - 242,  Score -  0.0\n",
      "Episode - 243,  Score -  0.0\n",
      "Episode - 244,  Score -  0.0\n",
      "Episode - 245,  Score -  0.0\n",
      "Episode - 246,  Score -  0.0\n",
      "Episode - 247,  Score -  0.0\n",
      "Episode - 248,  Score -  0.0\n",
      "Episode - 249,  Score -  0.0\n",
      "Gamma value - 0.7\n",
      "Number of Test Episodes - 250\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 18.28\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.3219\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.44495074e-03 1.16555199e-03 2.65632191e-04 7.79128117e-03]\n",
      " [3.99461653e-04 1.47411027e-05 2.57365759e-02 8.86753776e-03]\n",
      " [2.05116938e-02 3.57989492e-05 4.33287516e-05 5.08187621e-05]\n",
      " [3.55906485e-02 3.75678868e-06 3.72254183e-05 4.00647745e-05]\n",
      " [1.20570138e-02 1.68085158e-03 1.33326753e-03 1.22552561e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.36722924e-02 4.44071849e-03 1.00198826e-05 3.65120536e-07]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.77216824e-03 1.16545196e-03 2.37545351e-04 9.15355864e-03]\n",
      " [5.37032793e-03 5.64414888e-02 2.15820503e-05 1.13848560e-03]\n",
      " [6.47684750e-02 9.48941045e-04 5.29739942e-04 1.51918551e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.33327308e-02 1.49020746e-03 5.85629603e-02 5.44579970e-03]\n",
      " [3.15732112e-02 2.64911792e-01 3.28640390e-02 1.08830287e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Episode - 100,  Score -  0.0\n",
      "Episode - 101,  Score -  0.0\n",
      "Episode - 102,  Score -  0.0\n",
      "Episode - 103,  Score -  0.0\n",
      "Episode - 104,  Score -  0.0\n",
      "Episode - 105,  Score -  0.0\n",
      "Episode - 106,  Score -  0.0\n",
      "Episode - 107,  Score -  0.0\n",
      "Episode - 108,  Score -  0.0\n",
      "Episode - 109,  Score -  0.0\n",
      "Episode - 110,  Score -  0.0\n",
      "Episode - 111,  Score -  1.0\n",
      "Episode - 112,  Score -  0.0\n",
      "Episode - 113,  Score -  0.0\n",
      "Episode - 114,  Score -  1.0\n",
      "Episode - 115,  Score -  0.0\n",
      "Episode - 116,  Score -  0.0\n",
      "Episode - 117,  Score -  0.0\n",
      "Episode - 118,  Score -  0.0\n",
      "Episode - 119,  Score -  1.0\n",
      "Episode - 120,  Score -  0.0\n",
      "Episode - 121,  Score -  1.0\n",
      "Episode - 122,  Score -  0.0\n",
      "Episode - 123,  Score -  0.0\n",
      "Episode - 124,  Score -  0.0\n",
      "Episode - 125,  Score -  0.0\n",
      "Episode - 126,  Score -  0.0\n",
      "Episode - 127,  Score -  0.0\n",
      "Episode - 128,  Score -  0.0\n",
      "Episode - 129,  Score -  1.0\n",
      "Episode - 130,  Score -  0.0\n",
      "Episode - 131,  Score -  0.0\n",
      "Episode - 132,  Score -  0.0\n",
      "Episode - 133,  Score -  1.0\n",
      "Episode - 134,  Score -  0.0\n",
      "Episode - 135,  Score -  0.0\n",
      "Episode - 136,  Score -  1.0\n",
      "Episode - 137,  Score -  0.0\n",
      "Episode - 138,  Score -  0.0\n",
      "Episode - 139,  Score -  0.0\n",
      "Episode - 140,  Score -  0.0\n",
      "Episode - 141,  Score -  1.0\n",
      "Episode - 142,  Score -  0.0\n",
      "Episode - 143,  Score -  0.0\n",
      "Episode - 144,  Score -  0.0\n",
      "Episode - 145,  Score -  0.0\n",
      "Episode - 146,  Score -  1.0\n",
      "Episode - 147,  Score -  0.0\n",
      "Episode - 148,  Score -  0.0\n",
      "Episode - 149,  Score -  0.0\n",
      "Episode - 150,  Score -  0.0\n",
      "Episode - 151,  Score -  0.0\n",
      "Episode - 152,  Score -  0.0\n",
      "Episode - 153,  Score -  0.0\n",
      "Episode - 154,  Score -  0.0\n",
      "Episode - 155,  Score -  0.0\n",
      "Episode - 156,  Score -  0.0\n",
      "Episode - 157,  Score -  0.0\n",
      "Episode - 158,  Score -  1.0\n",
      "Episode - 159,  Score -  0.0\n",
      "Episode - 160,  Score -  0.0\n",
      "Episode - 161,  Score -  0.0\n",
      "Episode - 162,  Score -  0.0\n",
      "Episode - 163,  Score -  0.0\n",
      "Episode - 164,  Score -  0.0\n",
      "Episode - 165,  Score -  0.0\n",
      "Episode - 166,  Score -  0.0\n",
      "Episode - 167,  Score -  0.0\n",
      "Episode - 168,  Score -  0.0\n",
      "Episode - 169,  Score -  0.0\n",
      "Episode - 170,  Score -  0.0\n",
      "Episode - 171,  Score -  1.0\n",
      "Episode - 172,  Score -  0.0\n",
      "Episode - 173,  Score -  0.0\n",
      "Episode - 174,  Score -  0.0\n",
      "Episode - 175,  Score -  0.0\n",
      "Episode - 176,  Score -  0.0\n",
      "Episode - 177,  Score -  0.0\n",
      "Episode - 178,  Score -  0.0\n",
      "Episode - 179,  Score -  0.0\n",
      "Episode - 180,  Score -  0.0\n",
      "Episode - 181,  Score -  0.0\n",
      "Episode - 182,  Score -  0.0\n",
      "Episode - 183,  Score -  0.0\n",
      "Episode - 184,  Score -  0.0\n",
      "Episode - 185,  Score -  0.0\n",
      "Episode - 186,  Score -  0.0\n",
      "Episode - 187,  Score -  0.0\n",
      "Episode - 188,  Score -  0.0\n",
      "Episode - 189,  Score -  1.0\n",
      "Episode - 190,  Score -  0.0\n",
      "Episode - 191,  Score -  0.0\n",
      "Episode - 192,  Score -  0.0\n",
      "Episode - 193,  Score -  0.0\n",
      "Episode - 194,  Score -  0.0\n",
      "Episode - 195,  Score -  1.0\n",
      "Episode - 196,  Score -  0.0\n",
      "Episode - 197,  Score -  0.0\n",
      "Episode - 198,  Score -  0.0\n",
      "Episode - 199,  Score -  1.0\n",
      "Episode - 200,  Score -  0.0\n",
      "Episode - 201,  Score -  0.0\n",
      "Episode - 202,  Score -  0.0\n",
      "Episode - 203,  Score -  0.0\n",
      "Episode - 204,  Score -  0.0\n",
      "Episode - 205,  Score -  1.0\n",
      "Episode - 206,  Score -  0.0\n",
      "Episode - 207,  Score -  0.0\n",
      "Episode - 208,  Score -  0.0\n",
      "Episode - 209,  Score -  0.0\n",
      "Episode - 210,  Score -  0.0\n",
      "Episode - 211,  Score -  0.0\n",
      "Episode - 212,  Score -  0.0\n",
      "Episode - 213,  Score -  0.0\n",
      "Episode - 214,  Score -  0.0\n",
      "Episode - 215,  Score -  0.0\n",
      "Episode - 216,  Score -  0.0\n",
      "Episode - 217,  Score -  0.0\n",
      "Episode - 218,  Score -  0.0\n",
      "Episode - 219,  Score -  0.0\n",
      "Episode - 220,  Score -  0.0\n",
      "Episode - 221,  Score -  0.0\n",
      "Episode - 222,  Score -  0.0\n",
      "Episode - 223,  Score -  0.0\n",
      "Episode - 224,  Score -  0.0\n",
      "Episode - 225,  Score -  0.0\n",
      "Episode - 226,  Score -  0.0\n",
      "Episode - 227,  Score -  0.0\n",
      "Episode - 228,  Score -  0.0\n",
      "Episode - 229,  Score -  0.0\n",
      "Episode - 230,  Score -  0.0\n",
      "Episode - 231,  Score -  0.0\n",
      "Episode - 232,  Score -  0.0\n",
      "Episode - 233,  Score -  0.0\n",
      "Episode - 234,  Score -  0.0\n",
      "Episode - 235,  Score -  0.0\n",
      "Episode - 236,  Score -  0.0\n",
      "Episode - 237,  Score -  1.0\n",
      "Episode - 238,  Score -  0.0\n",
      "Episode - 239,  Score -  0.0\n",
      "Episode - 240,  Score -  0.0\n",
      "Episode - 241,  Score -  0.0\n",
      "Episode - 242,  Score -  0.0\n",
      "Episode - 243,  Score -  0.0\n",
      "Episode - 244,  Score -  0.0\n",
      "Episode - 245,  Score -  0.0\n",
      "Episode - 246,  Score -  0.0\n",
      "Episode - 247,  Score -  0.0\n",
      "Episode - 248,  Score -  0.0\n",
      "Episode - 249,  Score -  0.0\n",
      "Gamma value - 0.8\n",
      "Number of Test Episodes - 250\n",
      "Testing Score over time: 0.1\n",
      "Average num of Steps Per Episode: 7.212\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.4372\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[4.17523779e-02 1.96245885e-02 1.97519988e-02 1.42920991e-02]\n",
      " [2.86801836e-03 4.67958167e-03 8.39564388e-04 5.95239625e-02]\n",
      " [2.80815828e-02 2.87079578e-03 1.88902446e-03 3.49977586e-03]\n",
      " [1.88172838e-03 6.11500991e-03 1.81966790e-03 8.93312395e-03]\n",
      " [6.18977147e-02 7.32456400e-04 1.13824583e-02 1.59453491e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.73475741e-03 7.40638928e-06 3.02059382e-02 5.70214579e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.80241892e-02 1.94709816e-02 1.50861742e-02 1.61816405e-01]\n",
      " [2.66713365e-03 3.25255334e-01 2.82607342e-02 1.89483747e-03]\n",
      " [1.35859678e-01 2.30143051e-02 3.09891109e-03 2.04789743e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.57539278e-02 6.71035789e-02 7.20190550e-01 2.46972472e-02]\n",
      " [1.53653160e-01 1.57966713e-01 4.34779006e-01 1.62698843e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Episode - 100,  Score -  1.0\n",
      "Episode - 101,  Score -  0.0\n",
      "Episode - 102,  Score -  1.0\n",
      "Episode - 103,  Score -  1.0\n",
      "Episode - 104,  Score -  0.0\n",
      "Episode - 105,  Score -  0.0\n",
      "Episode - 106,  Score -  1.0\n",
      "Episode - 107,  Score -  1.0\n",
      "Episode - 108,  Score -  1.0\n",
      "Episode - 109,  Score -  1.0\n",
      "Episode - 110,  Score -  0.0\n",
      "Episode - 111,  Score -  1.0\n",
      "Episode - 112,  Score -  1.0\n",
      "Episode - 113,  Score -  1.0\n",
      "Episode - 114,  Score -  0.0\n",
      "Episode - 115,  Score -  1.0\n",
      "Episode - 116,  Score -  0.0\n",
      "Episode - 117,  Score -  1.0\n",
      "Episode - 118,  Score -  0.0\n",
      "Episode - 119,  Score -  1.0\n",
      "Episode - 120,  Score -  0.0\n",
      "Episode - 121,  Score -  1.0\n",
      "Episode - 122,  Score -  1.0\n",
      "Episode - 123,  Score -  1.0\n",
      "Episode - 124,  Score -  0.0\n",
      "Episode - 125,  Score -  1.0\n",
      "Episode - 126,  Score -  1.0\n",
      "Episode - 127,  Score -  0.0\n",
      "Episode - 128,  Score -  1.0\n",
      "Episode - 129,  Score -  0.0\n",
      "Episode - 130,  Score -  0.0\n",
      "Episode - 131,  Score -  0.0\n",
      "Episode - 132,  Score -  1.0\n",
      "Episode - 133,  Score -  1.0\n",
      "Episode - 134,  Score -  0.0\n",
      "Episode - 135,  Score -  0.0\n",
      "Episode - 136,  Score -  1.0\n",
      "Episode - 137,  Score -  0.0\n",
      "Episode - 138,  Score -  1.0\n",
      "Episode - 139,  Score -  1.0\n",
      "Episode - 140,  Score -  1.0\n",
      "Episode - 141,  Score -  0.0\n",
      "Episode - 142,  Score -  1.0\n",
      "Episode - 143,  Score -  1.0\n",
      "Episode - 144,  Score -  0.0\n",
      "Episode - 145,  Score -  1.0\n",
      "Episode - 146,  Score -  1.0\n",
      "Episode - 147,  Score -  0.0\n",
      "Episode - 148,  Score -  1.0\n",
      "Episode - 149,  Score -  0.0\n",
      "Episode - 150,  Score -  0.0\n",
      "Episode - 151,  Score -  1.0\n",
      "Episode - 152,  Score -  1.0\n",
      "Episode - 153,  Score -  0.0\n",
      "Episode - 154,  Score -  1.0\n",
      "Episode - 155,  Score -  1.0\n",
      "Episode - 156,  Score -  1.0\n",
      "Episode - 157,  Score -  0.0\n",
      "Episode - 158,  Score -  1.0\n",
      "Episode - 159,  Score -  1.0\n",
      "Episode - 160,  Score -  1.0\n",
      "Episode - 161,  Score -  1.0\n",
      "Episode - 162,  Score -  0.0\n",
      "Episode - 163,  Score -  1.0\n",
      "Episode - 164,  Score -  1.0\n",
      "Episode - 165,  Score -  1.0\n",
      "Episode - 166,  Score -  1.0\n",
      "Episode - 167,  Score -  1.0\n",
      "Episode - 168,  Score -  0.0\n",
      "Episode - 169,  Score -  0.0\n",
      "Episode - 170,  Score -  0.0\n",
      "Episode - 171,  Score -  1.0\n",
      "Episode - 172,  Score -  1.0\n",
      "Episode - 173,  Score -  1.0\n",
      "Episode - 174,  Score -  0.0\n",
      "Episode - 175,  Score -  0.0\n",
      "Episode - 176,  Score -  1.0\n",
      "Episode - 177,  Score -  1.0\n",
      "Episode - 178,  Score -  1.0\n",
      "Episode - 179,  Score -  0.0\n",
      "Episode - 180,  Score -  1.0\n",
      "Episode - 181,  Score -  0.0\n",
      "Episode - 182,  Score -  1.0\n",
      "Episode - 183,  Score -  1.0\n",
      "Episode - 184,  Score -  1.0\n",
      "Episode - 185,  Score -  0.0\n",
      "Episode - 186,  Score -  1.0\n",
      "Episode - 187,  Score -  0.0\n",
      "Episode - 188,  Score -  1.0\n",
      "Episode - 189,  Score -  0.0\n",
      "Episode - 190,  Score -  1.0\n",
      "Episode - 191,  Score -  1.0\n",
      "Episode - 192,  Score -  1.0\n",
      "Episode - 193,  Score -  0.0\n",
      "Episode - 194,  Score -  1.0\n",
      "Episode - 195,  Score -  1.0\n",
      "Episode - 196,  Score -  1.0\n",
      "Episode - 197,  Score -  1.0\n",
      "Episode - 198,  Score -  0.0\n",
      "Episode - 199,  Score -  0.0\n",
      "Episode - 200,  Score -  1.0\n",
      "Episode - 201,  Score -  1.0\n",
      "Episode - 202,  Score -  1.0\n",
      "Episode - 203,  Score -  1.0\n",
      "Episode - 204,  Score -  1.0\n",
      "Episode - 205,  Score -  1.0\n",
      "Episode - 206,  Score -  0.0\n",
      "Episode - 207,  Score -  1.0\n",
      "Episode - 208,  Score -  1.0\n",
      "Episode - 209,  Score -  0.0\n",
      "Episode - 210,  Score -  1.0\n",
      "Episode - 211,  Score -  1.0\n",
      "Episode - 212,  Score -  0.0\n",
      "Episode - 213,  Score -  0.0\n",
      "Episode - 214,  Score -  1.0\n",
      "Episode - 215,  Score -  0.0\n",
      "Episode - 216,  Score -  1.0\n",
      "Episode - 217,  Score -  0.0\n",
      "Episode - 218,  Score -  1.0\n",
      "Episode - 219,  Score -  1.0\n",
      "Episode - 220,  Score -  1.0\n",
      "Episode - 221,  Score -  0.0\n",
      "Episode - 222,  Score -  0.0\n",
      "Episode - 223,  Score -  0.0\n",
      "Episode - 224,  Score -  0.0\n",
      "Episode - 225,  Score -  1.0\n",
      "Episode - 226,  Score -  1.0\n",
      "Episode - 227,  Score -  0.0\n",
      "Episode - 228,  Score -  1.0\n",
      "Episode - 229,  Score -  0.0\n",
      "Episode - 230,  Score -  1.0\n",
      "Episode - 231,  Score -  1.0\n",
      "Episode - 232,  Score -  1.0\n",
      "Episode - 233,  Score -  1.0\n",
      "Episode - 234,  Score -  0.0\n",
      "Episode - 235,  Score -  1.0\n",
      "Episode - 236,  Score -  1.0\n",
      "Episode - 237,  Score -  0.0\n",
      "Episode - 238,  Score -  1.0\n",
      "Episode - 239,  Score -  0.0\n",
      "Episode - 240,  Score -  1.0\n",
      "Episode - 241,  Score -  1.0\n",
      "Episode - 242,  Score -  1.0\n",
      "Episode - 243,  Score -  1.0\n",
      "Episode - 244,  Score -  1.0\n",
      "Episode - 245,  Score -  1.0\n",
      "Episode - 246,  Score -  0.0\n",
      "Episode - 247,  Score -  0.0\n",
      "Episode - 248,  Score -  1.0\n",
      "Episode - 249,  Score -  1.0\n",
      "Gamma value - 0.9\n",
      "Number of Test Episodes - 250\n",
      "Testing Score over time: 0.652\n",
      "Average num of Steps Per Episode: 41.34\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.7, 0.8, 0.9]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    #qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 250     # Total test episodes\n",
    "    max_steps = 100                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = param                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1.0                 # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = 0.01             # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Gamma value - \" + str(gamma))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out Gamma value of 0.9 is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.42612\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.14814958e-01 1.36590361e-02 9.86018780e-03 1.14244951e-02]\n",
      " [4.63709212e-04 8.51859828e-04 2.35031799e-03 1.06897257e-01]\n",
      " [6.89378581e-03 2.78076304e-03 3.08988179e-03 1.86045587e-02]\n",
      " [6.22232537e-04 8.21766234e-04 7.72068254e-04 7.07581505e-03]\n",
      " [1.64809326e-01 2.66964842e-03 6.99263805e-03 4.29753467e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.05157579e-03 2.03652260e-05 1.19371561e-03 2.67175676e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.14996348e-03 8.43429862e-04 2.13165581e-03 1.24707220e-01]\n",
      " [3.10341822e-02 2.80838526e-01 1.04887207e-02 2.41779546e-02]\n",
      " [2.80500156e-01 2.87186010e-04 1.08970765e-02 1.23694601e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.74229284e-02 1.39986573e-01 6.34204013e-01 1.81986702e-02]\n",
      " [1.50906346e-01 9.41003571e-01 2.09904612e-01 1.93814583e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Gamma value - 0.9\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.77\n",
      "Average num of Steps Per Episode: 40.34\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.9]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 200                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = param                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1.0                 # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = 0.01             # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Gamma value - \" + str(gamma))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The testing score is 0.77.. which is 140% improvement from baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the value for Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.0\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 17.13\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.43104\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.34491446e-02 1.79561269e-02 2.31852046e-02 1.91855219e-02]\n",
      " [4.54047316e-03 5.03983417e-03 7.33760734e-03 1.77087789e-02]\n",
      " [1.54314782e-02 1.02497687e-02 1.55245336e-03 2.44765829e-03]\n",
      " [4.89899885e-03 1.86533742e-03 2.31612681e-02 3.21453269e-02]\n",
      " [2.41132046e-02 1.99580502e-02 1.93798515e-02 7.65397445e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.24831986e-02 2.91303741e-05 1.01375176e-05 1.60735578e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.49955036e-04 6.60044503e-03 2.64806096e-02 4.89750731e-02]\n",
      " [1.28654445e-02 7.29194684e-02 3.71215511e-02 8.65344227e-03]\n",
      " [2.34533832e-01 9.30245327e-03 9.24980100e-04 8.88356775e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.65093502e-03 1.65564085e-01 1.65423948e-01 7.00095676e-02]\n",
      " [1.84512991e-01 5.79836848e-01 1.46371553e-01 2.43774120e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.35\n",
      "Average num of Steps Per Episode: 21.22\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.4312\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[6.01932495e-02 2.27085031e-02 1.63276888e-02 2.11884298e-02]\n",
      " [5.78817185e-04 1.92837868e-03 2.23007792e-03 1.83317412e-02]\n",
      " [1.14314273e-02 1.81375681e-02 6.01817247e-03 1.05043090e-02]\n",
      " [5.05009852e-03 3.68954990e-04 8.46206171e-03 1.07196740e-02]\n",
      " [9.54975627e-02 1.76673727e-02 1.12341351e-02 3.30029648e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.93816878e-06 6.03631774e-05 3.35995522e-02 8.37807919e-09]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.56303218e-02 6.75927045e-02 4.75043390e-03 1.59245308e-01]\n",
      " [3.60622184e-03 2.63555279e-01 5.03352630e-03 6.37922088e-02]\n",
      " [6.67546859e-01 2.66442707e-03 2.33921931e-03 4.08450436e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.40566049e-02 1.82124874e-01 6.13967888e-01 1.83655865e-01]\n",
      " [7.20958486e-02 9.97213541e-01 9.80663985e-02 7.13235840e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  1.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.77\n",
      "Average num of Steps Per Episode: 42.36\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.44156\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[5.34216473e-02 1.59950711e-01 1.19127404e-02 1.13274707e-02]\n",
      " [2.88047609e-03 5.77432144e-03 2.23767202e-03 2.36567147e-02]\n",
      " [4.07093826e-03 2.93713346e-03 3.63292605e-03 1.16716143e-02]\n",
      " [3.66238644e-04 2.68462285e-04 2.20845272e-03 4.37256749e-03]\n",
      " [2.39660832e-01 1.12755476e-03 7.04346457e-03 5.44411814e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.81211175e-05 1.44740509e-02 1.14055751e-05 5.50349435e-06]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.01067027e-02 1.39868843e-02 1.24067708e-02 3.34820257e-01]\n",
      " [2.37588741e-02 6.00627271e-01 1.22394085e-02 4.42688318e-02]\n",
      " [1.00339580e-01 7.71599128e-03 1.03136979e-03 7.01860081e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.98988815e-02 4.56168613e-02 8.39807182e-01 4.85130340e-03]\n",
      " [2.17706966e-01 9.92119399e-01 1.14610901e-01 1.91629283e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.53\n",
      "Average num of Steps Per Episode: 51.37\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.44124\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[8.44284500e-02 1.61791659e-02 1.45372533e-02 2.77976168e-02]\n",
      " [2.81642275e-03 3.11219136e-03 1.92301773e-03 1.71195556e-02]\n",
      " [7.48019066e-03 1.21871338e-02 9.52320611e-04 2.91433618e-03]\n",
      " [9.12189335e-04 4.04223576e-04 2.14038619e-03 9.16557846e-03]\n",
      " [1.47574578e-01 2.66726649e-02 1.74990699e-02 1.88502927e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.94662081e-04 4.64740082e-04 3.37106757e-03 5.63915398e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.51556581e-02 4.74976828e-03 3.82255285e-02 1.87304737e-01]\n",
      " [3.04319128e-02 3.34323474e-01 1.82684437e-02 9.29918961e-02]\n",
      " [4.54324547e-01 1.24947043e-02 2.69708642e-02 5.21608951e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.73471908e-02 1.22734979e-01 7.28814200e-01 7.40763575e-02]\n",
      " [2.65874134e-01 9.48208546e-01 2.53975793e-01 1.96949959e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  1.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.77\n",
      "Average num of Steps Per Episode: 38.93\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.5, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 200                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = 0.9                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = param                # Exploration rate\n",
    "    max_epsilon = param             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = 0.01             # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Epsilon value - \" + str(epsilon))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both 0.8 and 1.0 goves a Testing score of 0.77 which is the highest score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Decay parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.43142\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[8.41233090e-02 2.31041951e-02 1.93229119e-02 6.85916076e-03]\n",
      " [1.42839770e-02 6.14347877e-03 1.03249379e-02 3.40018413e-02]\n",
      " [9.89932752e-03 1.47479017e-02 6.52708123e-02 1.80494314e-03]\n",
      " [3.93346460e-03 4.28097859e-03 4.91900887e-04 1.78763169e-02]\n",
      " [1.18492022e-01 2.85164950e-02 9.93915736e-03 1.33331427e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.25856618e-04 5.79682931e-06 3.59499973e-01 2.31066734e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [9.47975409e-03 6.40719247e-02 5.83047821e-02 1.35945634e-01]\n",
      " [2.52812595e-02 2.44646155e-01 9.77237475e-03 1.09194862e-01]\n",
      " [8.13949201e-01 5.10904517e-02 2.31514192e-04 2.11245190e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.05771554e-02 1.30995640e-02 3.17023081e-01 1.83699502e-01]\n",
      " [1.00256196e-01 3.48393415e-01 1.32039502e-01 1.11696960e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  1.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Decay value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.72\n",
      "Average num of Steps Per Episode: 43.58\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.0\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Decay value - 0.08\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 15.78\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.43406\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[2.48497944e-02 1.24969317e-02 6.26724331e-03 1.14664583e-02]\n",
      " [1.17446191e-03 1.24342627e-02 2.89088320e-03 2.99460398e-03]\n",
      " [1.40187459e-03 1.55980472e-03 2.06366373e-03 3.20894560e-02]\n",
      " [3.47752486e-03 4.01631464e-04 1.36802317e-03 2.28810209e-02]\n",
      " [3.96788721e-02 1.15393194e-02 1.46872354e-03 7.56451206e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.10405298e-04 7.72009388e-06 7.97808926e-03 3.21089694e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.29455927e-02 3.47461254e-02 1.30328382e-02 2.26660920e-01]\n",
      " [5.22046474e-03 3.08316487e-01 3.35471112e-03 3.01193931e-05]\n",
      " [4.24201946e-01 5.18022335e-03 6.19021016e-03 4.39333506e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.78436396e-02 4.53619005e-02 4.09302294e-01 7.73656658e-03]\n",
      " [2.00868813e-01 8.49684537e-01 2.89119298e-01 1.78171351e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  1.0\n",
      "Episode - 18,  Score -  1.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  1.0\n",
      "Episode - 38,  Score -  1.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  1.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Decay value - 0.005\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.75\n",
      "Average num of Steps Per Episode: 40.8\n",
      "*************************  Q-Learning  ********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.0\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Decay value - 0.1\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 19.21\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.01, 0.08, 0.005, 0.1]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 200                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = 0.9                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1                # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = param            # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Decay value - \" + str(param))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decay Param of 0.005 and 0.01 gives the best values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying new policy of Min instead of Max value from Q table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 0.00012\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.21   0.9289 0.0819]\n",
      " [0.     0.     0.     0.    ]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 13.27\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.01]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 200                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = 0.9                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1                # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = param            # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.min(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Epsilon value - \" + str(epsilon))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new Policy of Min as expected didnt improve the Learning \n",
    "Lets try a new Reward Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Reward policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reward of +100 when Success \n",
    "Reward of -2 when No Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: -7.35268\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[-11.04898008  -4.39008332 -11.16613857 -11.18037783]\n",
      " [ -9.91643961  -1.68715893 -10.45826472 -11.0694725 ]\n",
      " [-11.63802725 -11.5350495   -0.23315288 -11.51716259]\n",
      " [ -9.73681421  -8.82895924  -2.57013618 -10.87534601]\n",
      " [ -7.49742064  -0.27944429 -10.58494368  -8.26860047]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -7.75679114  -0.99473001  -6.78227131  -3.40690273]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -9.94020587  -0.58243842  -9.18496213   2.4545803 ]\n",
      " [ -5.91753988  29.77307947   0.29129587  -6.76680694]\n",
      " [ -6.29087658  56.21844917  -4.81176137  -5.88881881]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -6.36456472  21.39684802  -5.62187622  -6.45798325]\n",
      " [ -3.5423052   -3.68038186  -1.81224701  88.50405102]\n",
      " [  0.           0.           0.           0.        ]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.05\n",
      "Average num of Steps Per Episode: 5.3\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: -7.5442\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[-10.21368575  -6.54262311 -10.7524428  -10.65881157]\n",
      " [-11.69984953 -10.27683921  -6.59646684 -11.2395281 ]\n",
      " [ -9.83242541  -9.91170854  -5.2749594   -8.53608991]\n",
      " [-11.73261523  -2.27125503 -11.92647935 -11.63096855]\n",
      " [ -9.77833336  -3.07450206 -10.31799818  -9.75015124]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -3.59651986  -3.23634589  -3.7441294   -5.7822007 ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -9.10859942   2.6795541   -6.29387878  -8.78486491]\n",
      " [ -1.70998368  -6.21351022   7.05074339  -6.75353365]\n",
      " [ -5.66909231   7.34719725  -4.84963298  -5.70614394]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -5.54468346   0.17757219  -5.47933562   0.78544772]\n",
      " [ -2.55534708   1.04788116  29.68420625  -0.03227343]\n",
      " [  0.           0.           0.           0.        ]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.03\n",
      "Average num of Steps Per Episode: 3.82\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.01, 0.005]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 200                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = 0.9                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1                # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = param            # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if(reward == 1):\n",
    "                reward = 100\n",
    "            elif(reward == 0):\n",
    "                reward = -2\n",
    "            \n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Epsilon value - \" + str(epsilon))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reward policy didnt help much, lets try some more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Reward policy\n",
    "\n",
    "Reward of +10 when Success \n",
    "Reward of 0 when No Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 4.285\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[2.44679175e-01 1.28968463e-01 1.11506113e-01 1.30342101e-01]\n",
      " [2.40680403e-02 7.20976521e-02 3.69372192e-03 1.46798220e-01]\n",
      " [3.33635129e-02 1.09896970e-01 4.80521179e-02 1.08278641e-02]\n",
      " [8.20527766e-02 9.66410021e-03 9.73918251e-02 1.20964319e-01]\n",
      " [9.87093763e-01 3.74733345e-02 1.81238621e-01 8.96754718e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.96810757e-01 6.15082120e-04 3.67814006e-04 3.87806863e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.49469643e-02 1.32182483e-01 2.38132536e-01 1.92727110e+00]\n",
      " [9.05964866e-02 4.67959817e+00 1.01089963e+00 4.30693615e-01]\n",
      " [2.78375814e+00 3.39036924e-03 1.19849812e-01 2.88521581e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.15147835e-01 7.51937654e-01 3.15808849e+00 1.06521609e+00]\n",
      " [1.03986732e+00 3.78249670e+00 9.84044121e+00 1.09797127e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  1.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  1.0\n",
      "Episode - 11,  Score -  1.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  1.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  1.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  1.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  1.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  1.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  1.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  1.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  1.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.67\n",
      "Average num of Steps Per Episode: 39.46\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 4.2616\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.01358485e-01 7.29656430e-01 1.05716320e-01 1.46213212e-01]\n",
      " [7.17611009e-03 9.15389648e-02 4.67005070e-02 6.65725391e-01]\n",
      " [9.72670752e-02 5.49582496e-01 4.94727636e-02 5.60568912e-02]\n",
      " [7.28126366e-03 2.93209713e-04 4.73838881e-03 2.52494692e-01]\n",
      " [2.57979263e+00 3.00823377e-01 2.79675413e-01 8.59917274e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.31754599e+00 2.19423312e-06 5.46506247e-04 6.63988634e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.83322859e-01 7.83176525e-02 9.92411193e-02 4.04665197e+00]\n",
      " [1.43048568e-01 5.92659029e+00 6.48333086e-02 1.41652693e-01]\n",
      " [7.93507505e+00 8.07990227e-02 5.65608762e-02 8.12869300e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.30084260e-01 6.08891551e-01 7.34252410e+00 4.77945282e-01]\n",
      " [1.80600560e+00 9.37085865e+00 1.35601541e+00 1.47959066e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  1.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  1.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  1.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  1.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  1.0\n",
      "Episode - 43,  Score -  1.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  1.0\n",
      "Episode - 49,  Score -  1.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  1.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  1.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  1.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  1.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  1.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.52\n",
      "Average num of Steps Per Episode: 33.33\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.01, 0.005]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 200                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = 0.9                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1                # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = param            # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if(reward == 1):\n",
    "                reward = 10\n",
    "            elif(reward == 0):\n",
    "                reward = 0\n",
    "            \n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Epsilon value - \" + str(epsilon))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This policy is also good as the testing score is 0.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Reward Policy - \n",
    "\n",
    "Reward of +500 when Success \n",
    "Reward of -2 when No Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 17.48968\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[-11.02717612  -6.02998732 -10.10873362 -10.28131196]\n",
      " [ -9.43918136  -2.59590328  -9.72935583  -9.47410708]\n",
      " [  1.14925881 -10.07934748 -10.79468453 -10.41307167]\n",
      " [-11.07460436 -10.82594105  -4.64120653 -11.41589826]\n",
      " [ -7.24361966  -3.60112798  -6.32096063  -6.15187649]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -3.61079249   1.08343997  -4.55926024  -2.76824815]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -7.69812146  49.50082959  -6.90895046  -7.42131445]\n",
      " [ -5.43291986  20.13789194  -0.36734824  -5.83884427]\n",
      " [ -3.69316262   4.65281863  -3.51019807  -3.57489779]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -3.59739751 281.45936888  -5.65688434  -4.88382409]\n",
      " [ 13.64798828   8.81836381 129.97755898  20.43716952]\n",
      " [  0.           0.           0.           0.        ]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  1.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  1.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.04\n",
      "Average num of Steps Per Episode: 4.24\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 19.61148\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[-1.28000776e+01 -6.85630137e+00 -6.62073858e+00 -1.19168451e+01]\n",
      " [-1.18823029e+01 -1.18007440e+01 -5.38513020e+00 -1.17208759e+01]\n",
      " [-1.05601656e+01 -3.78861772e+00 -1.05566888e+01 -1.02190924e+01]\n",
      " [-4.85663602e+00 -4.39380639e+00 -5.40374197e+00 -9.41415847e+00]\n",
      " [-9.29217598e+00 -9.28465678e+00 -7.83453216e-01 -8.73420128e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-4.40824181e+00 -1.99486396e+00 -4.79075226e+00 -3.69694659e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-7.34917533e+00 -7.73296805e+00  1.11786801e-01 -7.27347514e+00]\n",
      " [-2.55434514e+00  2.61539651e+02 -1.68429311e+00 -1.59327038e+00]\n",
      " [-2.98577449e+00  1.11734556e+02 -2.41976556e+00 -3.46479702e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.36039671e+01  1.20002013e+01  1.95704646e+02  3.48621029e+01]\n",
      " [ 5.51048249e+01  4.91190483e+02  5.21808692e+01  2.41178419e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  1.0\n",
      "Episode - 74,  Score -  1.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.07\n",
      "Average num of Steps Per Episode: 4.15\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.01, 0.005]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 200                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = 0.9                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1                # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = param            # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if(reward == 1):\n",
    "                reward = 500\n",
    "            elif(reward == 0):\n",
    "                reward = -2\n",
    "            \n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Epsilon value - \" + str(epsilon))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4th Reward Policy - \n",
    "\n",
    "Reward of +50 when Success \n",
    "Reward of 0 when No Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 21.858\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.99022704e+00 2.65016339e-01 6.42286512e-01 4.58406268e-01]\n",
      " [6.43307841e-02 4.56114626e-02 1.17586524e-01 6.23732942e-01]\n",
      " [6.55024862e-02 5.68952433e-02 1.26702287e+01 1.55917741e-01]\n",
      " [4.50490813e-02 3.40597487e-02 2.79689391e-02 2.36490869e-01]\n",
      " [1.80546742e+00 3.41537596e-01 7.08196644e-01 2.71596401e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.20818438e+00 8.41212171e-06 4.64424487e-03 3.21027487e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.32338961e-01 2.42577734e-02 1.07186867e+00 9.53049568e+00]\n",
      " [2.65013071e-01 1.09478544e+01 8.23514974e-01 2.12318296e+00]\n",
      " [5.63143729e-01 3.22651786e+01 2.52943804e-01 1.10366888e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.22199654e+00 2.38406457e-01 2.96765691e+01 3.03012431e+00]\n",
      " [7.63683313e+00 4.88595120e+01 1.13213664e+01 8.65255223e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  1.0\n",
      "Episode - 1,  Score -  1.0\n",
      "Episode - 2,  Score -  1.0\n",
      "Episode - 3,  Score -  1.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  1.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  1.0\n",
      "Episode - 9,  Score -  1.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  1.0\n",
      "Episode - 14,  Score -  1.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  1.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  1.0\n",
      "Episode - 22,  Score -  1.0\n",
      "Episode - 23,  Score -  1.0\n",
      "Episode - 24,  Score -  1.0\n",
      "Episode - 25,  Score -  1.0\n",
      "Episode - 26,  Score -  1.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  1.0\n",
      "Episode - 29,  Score -  1.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  1.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  1.0\n",
      "Episode - 40,  Score -  1.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  1.0\n",
      "Episode - 45,  Score -  1.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  1.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  1.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  1.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  1.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  1.0\n",
      "Episode - 57,  Score -  1.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  1.0\n",
      "Episode - 60,  Score -  1.0\n",
      "Episode - 61,  Score -  1.0\n",
      "Episode - 62,  Score -  1.0\n",
      "Episode - 63,  Score -  1.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  1.0\n",
      "Episode - 66,  Score -  1.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  1.0\n",
      "Episode - 69,  Score -  1.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  1.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  1.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  1.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  1.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  1.0\n",
      "Episode - 87,  Score -  1.0\n",
      "Episode - 88,  Score -  1.0\n",
      "Episode - 89,  Score -  1.0\n",
      "Episode - 90,  Score -  1.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  1.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  1.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  1.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.6\n",
      "Average num of Steps Per Episode: 30.37\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 21.294\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[6.69571493e+00 7.57903203e-01 2.46420595e-01 1.25261997e+00]\n",
      " [5.83475181e-02 1.14203063e-01 1.17188844e-01 2.63863647e+00]\n",
      " [1.14971275e-01 1.13480194e-01 6.92946913e-02 5.36190786e-01]\n",
      " [2.33312639e-03 5.31291771e-02 1.97807416e-03 1.45772592e-01]\n",
      " [6.27429883e+00 7.35200505e-02 6.74361657e-01 2.61375032e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.13712106e-03 2.60075192e-03 1.58594248e+00 2.69646379e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.12901002e-01 1.86122396e-01 8.29416445e-01 5.61424554e+00]\n",
      " [6.57290408e-01 5.81802490e+00 1.80586196e+00 1.81070507e+00]\n",
      " [6.93113714e+00 2.43075584e+00 1.54569268e-01 1.28529126e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.50483643e-01 4.84821211e+00 1.13675979e+01 4.98042657e+00]\n",
      " [1.12301658e+01 1.09025288e+01 4.96146188e+00 1.08555996e+01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  0.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  0.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  0.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  0.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  0.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  0.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  0.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  0.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  0.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  0.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  0.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  0.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  0.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  0.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  0.0\n",
      "Episode - 92,  Score -  0.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  0.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.0\n",
      "Average num of Steps Per Episode: 75.87\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.01, 0.005]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 200                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = 0.9                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1                # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = param            # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if(reward == 1):\n",
    "                reward = 50\n",
    "            elif(reward == 0):\n",
    "                reward = 0\n",
    "            \n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Epsilon value - \" + str(epsilon))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also a good model, and can be tuned more to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Size -  4\n",
      "State Size -  16\n",
      "*************************  Q-Learning  ********************************\n",
      "Number of Episodes - 50000\n",
      "Training Score over time: 43.048\n",
      "Average Epsilon value is 0, since Max steps are not reached\n",
      "[[1.41675231e+00 1.45051184e+00 1.47714279e+00 3.67631025e-01]\n",
      " [3.77406784e-03 9.79907443e-02 9.06458049e-02 9.01922857e-01]\n",
      " [1.84505926e-01 4.89281330e-01 8.49309686e-02 8.33642205e-02]\n",
      " [8.14303126e-04 3.00543620e-03 6.09220219e-02 1.51042153e+00]\n",
      " [3.60184912e+00 3.75110725e-03 5.77779317e-01 6.90627258e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.59006299e-03 7.40441305e-04 5.08437764e+01 4.40814464e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.45038064e+00 1.56040354e+00 7.32690750e-01 9.07826619e+00]\n",
      " [1.20378701e-01 1.37135480e+00 2.78168999e-02 8.80109220e+00]\n",
      " [3.06608087e+01 4.17059301e-02 2.61139111e-01 5.21594655e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.68297543e-02 1.39022827e+01 4.28355025e+01 1.73917822e+00]\n",
      " [7.15702015e+00 7.40082614e+01 1.89557219e+01 1.01475825e+01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      " \n",
      "*************************  Q-Testing  ********************************\n",
      "Episode - 0,  Score -  0.0\n",
      "Episode - 1,  Score -  0.0\n",
      "Episode - 2,  Score -  0.0\n",
      "Episode - 3,  Score -  0.0\n",
      "Episode - 4,  Score -  0.0\n",
      "Episode - 5,  Score -  0.0\n",
      "Episode - 6,  Score -  0.0\n",
      "Episode - 7,  Score -  1.0\n",
      "Episode - 8,  Score -  0.0\n",
      "Episode - 9,  Score -  0.0\n",
      "Episode - 10,  Score -  0.0\n",
      "Episode - 11,  Score -  0.0\n",
      "Episode - 12,  Score -  0.0\n",
      "Episode - 13,  Score -  0.0\n",
      "Episode - 14,  Score -  0.0\n",
      "Episode - 15,  Score -  1.0\n",
      "Episode - 16,  Score -  0.0\n",
      "Episode - 17,  Score -  0.0\n",
      "Episode - 18,  Score -  0.0\n",
      "Episode - 19,  Score -  0.0\n",
      "Episode - 20,  Score -  1.0\n",
      "Episode - 21,  Score -  0.0\n",
      "Episode - 22,  Score -  0.0\n",
      "Episode - 23,  Score -  0.0\n",
      "Episode - 24,  Score -  0.0\n",
      "Episode - 25,  Score -  0.0\n",
      "Episode - 26,  Score -  0.0\n",
      "Episode - 27,  Score -  1.0\n",
      "Episode - 28,  Score -  0.0\n",
      "Episode - 29,  Score -  0.0\n",
      "Episode - 30,  Score -  0.0\n",
      "Episode - 31,  Score -  0.0\n",
      "Episode - 32,  Score -  0.0\n",
      "Episode - 33,  Score -  1.0\n",
      "Episode - 34,  Score -  0.0\n",
      "Episode - 35,  Score -  0.0\n",
      "Episode - 36,  Score -  0.0\n",
      "Episode - 37,  Score -  0.0\n",
      "Episode - 38,  Score -  0.0\n",
      "Episode - 39,  Score -  0.0\n",
      "Episode - 40,  Score -  0.0\n",
      "Episode - 41,  Score -  1.0\n",
      "Episode - 42,  Score -  0.0\n",
      "Episode - 43,  Score -  0.0\n",
      "Episode - 44,  Score -  0.0\n",
      "Episode - 45,  Score -  0.0\n",
      "Episode - 46,  Score -  1.0\n",
      "Episode - 47,  Score -  0.0\n",
      "Episode - 48,  Score -  0.0\n",
      "Episode - 49,  Score -  0.0\n",
      "Episode - 50,  Score -  0.0\n",
      "Episode - 51,  Score -  0.0\n",
      "Episode - 52,  Score -  0.0\n",
      "Episode - 53,  Score -  0.0\n",
      "Episode - 54,  Score -  0.0\n",
      "Episode - 55,  Score -  1.0\n",
      "Episode - 56,  Score -  0.0\n",
      "Episode - 57,  Score -  0.0\n",
      "Episode - 58,  Score -  0.0\n",
      "Episode - 59,  Score -  0.0\n",
      "Episode - 60,  Score -  0.0\n",
      "Episode - 61,  Score -  0.0\n",
      "Episode - 62,  Score -  0.0\n",
      "Episode - 63,  Score -  0.0\n",
      "Episode - 64,  Score -  0.0\n",
      "Episode - 65,  Score -  0.0\n",
      "Episode - 66,  Score -  0.0\n",
      "Episode - 67,  Score -  1.0\n",
      "Episode - 68,  Score -  0.0\n",
      "Episode - 69,  Score -  0.0\n",
      "Episode - 70,  Score -  1.0\n",
      "Episode - 71,  Score -  0.0\n",
      "Episode - 72,  Score -  0.0\n",
      "Episode - 73,  Score -  0.0\n",
      "Episode - 74,  Score -  0.0\n",
      "Episode - 75,  Score -  1.0\n",
      "Episode - 76,  Score -  0.0\n",
      "Episode - 77,  Score -  1.0\n",
      "Episode - 78,  Score -  0.0\n",
      "Episode - 79,  Score -  0.0\n",
      "Episode - 80,  Score -  1.0\n",
      "Episode - 81,  Score -  0.0\n",
      "Episode - 82,  Score -  1.0\n",
      "Episode - 83,  Score -  0.0\n",
      "Episode - 84,  Score -  0.0\n",
      "Episode - 85,  Score -  0.0\n",
      "Episode - 86,  Score -  0.0\n",
      "Episode - 87,  Score -  0.0\n",
      "Episode - 88,  Score -  0.0\n",
      "Episode - 89,  Score -  0.0\n",
      "Episode - 90,  Score -  0.0\n",
      "Episode - 91,  Score -  1.0\n",
      "Episode - 92,  Score -  1.0\n",
      "Episode - 93,  Score -  0.0\n",
      "Episode - 94,  Score -  0.0\n",
      "Episode - 95,  Score -  0.0\n",
      "Episode - 96,  Score -  0.0\n",
      "Episode - 97,  Score -  0.0\n",
      "Episode - 98,  Score -  1.0\n",
      "Episode - 99,  Score -  0.0\n",
      "Epsilon value - 0.01\n",
      "Number of Test Episodes - 100\n",
      "Testing Score over time: 0.17\n",
      "Average num of Steps Per Episode: 21.5\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env.render()\n",
    "\n",
    "action_size = env.action_space.n\n",
    "print('Action Size - ',action_size)\n",
    "\n",
    "state_size = env.observation_space.n\n",
    "print('State Size - ', state_size)\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "#print(qtable)\n",
    "\n",
    "tuning_params = [0.01]\n",
    "\n",
    "\n",
    "for param in tuning_params:    \n",
    "\n",
    "    qtable = np.zeros((state_size, action_size))\n",
    "    total_episodes = 50000        # Total episodes\n",
    "    total_test_episodes = 100     # Total test episodes\n",
    "    max_steps = 200                # Max steps per episode\n",
    "\n",
    "    learning_rate = 0.7          # Learning rate\n",
    "    gamma = 0.9                 # Discounting rate\n",
    "\n",
    "    # Exploration parameters\n",
    "    epsilon = 1                # Exploration rate\n",
    "    max_epsilon = 1.0             # Exploration probability at start\n",
    "    min_epsilon = 0.01            # Minimum exploration probability \n",
    "    decay_rate = param            # Exponential decay rate for exploration prob\n",
    "\n",
    "\n",
    "    rewards = []\n",
    "    avg_epsilon = []\n",
    "\n",
    "    print('*************************  Q-Learning  ********************************')\n",
    "    # 2 For life or until learning is stopped\n",
    "    for episode in range(total_episodes):\n",
    "        # Reset the environment\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # 3. Choose an action a in the current world state (s)\n",
    "            ## First we randomize a number\n",
    "            exp_exp_tradeoff = random.uniform(0,1)\n",
    "\n",
    "            ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "            if exp_exp_tradeoff > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "\n",
    "            # Else doing a random choice --> exploration\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            if(reward == 1):\n",
    "                reward = 100\n",
    "            elif(reward == 0):\n",
    "                reward = 0\n",
    "            \n",
    "            # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "            qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
    "                                        np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "\n",
    "            total_rewards += reward\n",
    "            # Our new state is state\n",
    "            state = new_state\n",
    "\n",
    "            # If done : finish episode\n",
    "            if done == True: \n",
    "                break\n",
    "\n",
    "            if(step == max_steps-1):\n",
    "            #print('Max Step Reached for Episode - ', episode)\n",
    "            #print('Epsilon value at Max Step - ', epsilon)\n",
    "                avg_epsilon.append(epsilon)\n",
    "\n",
    "        # Reduce epsilon (because we need less and less exploration)\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    print(\"Number of Episodes - \" + str(total_episodes))\n",
    "    print (\"Training Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "    try:\n",
    "        print(\"Average Epsilon value when max steps is reached: \" + str(sum(avg_epsilon)/len(avg_epsilon)))\n",
    "    except:\n",
    "        print(\"Average Epsilon value is 0, since Max steps are not reached\")\n",
    "        \n",
    "    print(qtable)\n",
    "    print(\" \")\n",
    "\n",
    "    env.reset()\n",
    "    rewards = []\n",
    "    avg_steps = []\n",
    "\n",
    "    print('*************************  Q-Testing  ********************************')\n",
    "    \n",
    "    for episode in range(total_test_episodes):\n",
    "        state = env.reset()\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "\n",
    "            # UNCOMMENT IT IF YOU WANT TO SEE OUR AGENT PLAYING\n",
    "            #env.render()\n",
    "            # Take the action (index) that have the maximum expected future reward given that state\n",
    "            action = np.argmax(qtable[state,:])\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            total_rewards += reward\n",
    "\n",
    "            if done:\n",
    "                #env.render()\n",
    "                print (\"Episode - \"+ str(episode) + \",  Score - \", total_rewards)\n",
    "                #avg_steps.append(step)\n",
    "                break\n",
    "            state = new_state\n",
    "        avg_steps.append(step)\n",
    "        rewards.append(total_rewards)\n",
    "\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    print(\"Epsilon value - \" + str(epsilon))\n",
    "    print(\"Number of Test Episodes - \" + str(total_test_episodes))\n",
    "    print (\"Testing Score over time: \" +  str(sum(rewards)/total_test_episodes))\n",
    "    print(\"Average num of Steps Per Episode: \" + str(sum(avg_steps)/total_test_episodes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Over Time for baseline Model\n",
    "\n",
    "### 0.37\n",
    "\n",
    "## Best Score Over Time after Parameter Tuning\n",
    "\n",
    "### 0.77\n",
    "\n",
    "### Improvement of around 108%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions- \n",
    "\n",
    "##### 1. Establish a baseline performance. How well did your RL Q-learning do on your problem?\n",
    "\n",
    "The Q-learning did perform decently with the baseline parameters.\n",
    "I got a Training Score(Average rewards) of 0.32 and Testing 0.37. \n",
    "The average number of steps per episode is 27.88\n",
    "\n",
    "After tuning for best parameters, i got a score of 0.77. \n",
    "\n",
    "##### 2. What are the states, the actions and the size of the Q-table?\n",
    "\n",
    "SFFF       (S: starting point, safe)\n",
    "FHFH       (F: frozen surface, safe)\n",
    "FFFH       (H: hole, fall to your doom)\n",
    "HFFG       (G: goal, where the frisbee is located)\n",
    "\n",
    "Actions are - Up, down, right, left\n",
    "\n",
    "Size of Q table - (state_size, action_size) (16,4)\n",
    "\n",
    "##### 3. What are the rewards? Why did you choose them?\n",
    "\n",
    "The default reward policy is - \n",
    "1 for each success\n",
    "0 for failure\n",
    "\n",
    "I also tried 3 more Reward Policies, but this is the best one. \n",
    "\n",
    "##### 4. How did you choose alpha and gamma in the following equation?\n",
    "\n",
    "The alpha and gamma were choosen based on domain knowledge after reading, as Gamma controls the Future reward rate discounted in time. and Alpha is the learning rate and should not be very high or very low. I tried with different values and came up with the best ones. \n",
    "\n",
    "##### 5. Try at least one additional value for alpha and gamma. How did it change the baseline performance?\n",
    "I tried 4-5 new values and 1-2 of them significantly improved the Score. \n",
    "\n",
    "##### 6. Try a policy other than maxQ(s', a'). How did it change the baseline performance?\n",
    "I tried MinQ policy, but it did not improve the performance. \n",
    "\n",
    "##### 7. How did you choose your decay rate and starting epsilon? Try at least one additional value for epsilonand the decay rate. How did it change the baseline performance? \n",
    "The starting epsilon was set to 1 and we need maximum exploration at the start. I tried 4 different values and saw that 1 and 0.8 can be used. Decay rate is 0.01 and 0.005 is the  best ones. They improved the performance. \n",
    "Decay rate is used to transition from Exploration state to Exploitation state. \n",
    "\n",
    "##### 8. What is the value of epsilon when if you reach the max steps per episode?\n",
    "0.010407262485706588\n",
    "\n",
    "##### 9. What is the average number of steps taken per episode?\n",
    "27.88 steps per episode for base model.  \n",
    "43.58 for tuned model. \n",
    "\n",
    "##### 10. Does Q-learning use value-based or policy-based iteration?\n",
    "Q-learning uses value-based iteration as it uses a policy to update the Q values. It is a off-policy. \n",
    "\n",
    "##### 11. What is meant by expected lifetime value in the Bellman equation?\n",
    "Expected Lifetime value in bellman equation is the Total Expected Reward for the Agent in its lifetime which consists of the max of Future reward discounted in time. The lifetime of the agent is one Episode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
