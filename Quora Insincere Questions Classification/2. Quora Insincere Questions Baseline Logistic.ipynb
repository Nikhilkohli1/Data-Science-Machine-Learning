{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Insincere Question Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract \n",
    "\n",
    "The objective is to predict whether a question asked on Quora is sincere or not.\n",
    "An insincere question is defined as a question intended to make a statement rather than look for helpful answers. Some characteristics that can signify that a question is insincere:\n",
    "\n",
    "- Has a non-neutral tone\n",
    "- Has an exaggerated tone to underscore a point about a group of people\n",
    "- Is rhetorical and meant to imply a statement about a group of people\n",
    "- Is disparaging or inflammatory\n",
    "- Suggests a discriminatory idea against a protected class of people, or seeks confirmation of a stereotype\n",
    "- Makes disparaging attacks/insults against a specific person or group of people\n",
    "\n",
    "### Baseline - Logistic Regression with tf-idf\n",
    "\n",
    "I will try various Deep Learning Algorithms to see which works best of this dataset like LSTM, SimpleRNN, Conv1D, GRU etc. I will also use pre-trained word embeddings in few algorithms. As a baseline, I will use Naive Bayes and Logistic regression for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import time, gc, warnings\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, Conv1D, GRU, SimpleRNN\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "punctuations = string.punctuation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'N:\\ADVANCE DATA SCIENCE\\ASSIGNMENTS\\Assignment 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Quora = pd.read_csv('quora_questions_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69d762db89f677e2b38d</td>\n",
       "      <td>How can I live fully happier life?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de052885a7cb6483c482</td>\n",
       "      <td>What is the difference between IT and computer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5cf30b565aa71a3ce65c</td>\n",
       "      <td>Why a suit is the dress code of business people?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a2483d6b6debff584f87</td>\n",
       "      <td>How can you get the earnest money loan for a b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c93fef8401e553bbee16</td>\n",
       "      <td>Why would an atheist care if others celebrate ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  69d762db89f677e2b38d                 How can I live fully happier life?   \n",
       "1  de052885a7cb6483c482  What is the difference between IT and computer...   \n",
       "2  5cf30b565aa71a3ce65c   Why a suit is the dress code of business people?   \n",
       "3  a2483d6b6debff584f87  How can you get the earnest money loan for a b...   \n",
       "4  c93fef8401e553bbee16  Why would an atheist care if others celebrate ...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Quora[df_Quora.target == 0].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61266</th>\n",
       "      <td>9d91dabfc5358b6e9b4a</td>\n",
       "      <td>Has Trump (since becoming president), ever com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61267</th>\n",
       "      <td>cafdbedf2152a331cf88</td>\n",
       "      <td>Why Turkish people and Iranians look white des...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61268</th>\n",
       "      <td>877e654f6097f6dde056</td>\n",
       "      <td>Do Hungarians envy Romania, because they are b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61269</th>\n",
       "      <td>341b769d29966cae4b16</td>\n",
       "      <td>I just got a message that my answer had been \"...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61270</th>\n",
       "      <td>136b7b3b0dc24a6256c0</td>\n",
       "      <td>What does black man cum taste like?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        qid  \\\n",
       "61266  9d91dabfc5358b6e9b4a   \n",
       "61267  cafdbedf2152a331cf88   \n",
       "61268  877e654f6097f6dde056   \n",
       "61269  341b769d29966cae4b16   \n",
       "61270  136b7b3b0dc24a6256c0   \n",
       "\n",
       "                                           question_text  target  \n",
       "61266  Has Trump (since becoming president), ever com...       1  \n",
       "61267  Why Turkish people and Iranians look white des...       1  \n",
       "61268  Do Hungarians envy Romania, because they are b...       1  \n",
       "61269  I just got a message that my answer had been \"...       1  \n",
       "61270                What does black man cum taste like?       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Quora[df_Quora.target == 1].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(question):\n",
    "    \"\"\"\n",
    "    This function receives comments and returns clean word-list\n",
    "    \"\"\"\n",
    "    question = question.lower()\n",
    "    question = re.sub(\"\\\\n\", \"\", question)\n",
    "    question = re.sub(\"\\'\", \"\", question)\n",
    "    question = re.sub(\"\\W+\", \" \", question)\n",
    "    \n",
    "    #Split the sentences into words\n",
    "    words = tokenizer.tokenize(question)\n",
    "    \n",
    "    words = [lem.lemmatize(word, \"v\") for word in words]\n",
    "    words = [w for w in words if w not in punctuations]\n",
    "    #words = [''.join(x for x in w if x.isalpha()) for w in words]\n",
    "\n",
    "    clean_sen = \" \".join(words)\n",
    "    \n",
    "    return clean_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "      <th>question_text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69d762db89f677e2b38d</td>\n",
       "      <td>How can I live fully happier life?</td>\n",
       "      <td>0</td>\n",
       "      <td>how can i live fully happier life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de052885a7cb6483c482</td>\n",
       "      <td>What is the difference between IT and computer...</td>\n",
       "      <td>0</td>\n",
       "      <td>what be the difference between it and computer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5cf30b565aa71a3ce65c</td>\n",
       "      <td>Why a suit is the dress code of business people?</td>\n",
       "      <td>0</td>\n",
       "      <td>why a suit be the dress code of business people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a2483d6b6debff584f87</td>\n",
       "      <td>How can you get the earnest money loan for a b...</td>\n",
       "      <td>0</td>\n",
       "      <td>how can you get the earnest money loan for a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c93fef8401e553bbee16</td>\n",
       "      <td>Why would an atheist care if others celebrate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>why would an atheist care if others celebrate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  69d762db89f677e2b38d                 How can I live fully happier life?   \n",
       "1  de052885a7cb6483c482  What is the difference between IT and computer...   \n",
       "2  5cf30b565aa71a3ce65c   Why a suit is the dress code of business people?   \n",
       "3  a2483d6b6debff584f87  How can you get the earnest money loan for a b...   \n",
       "4  c93fef8401e553bbee16  Why would an atheist care if others celebrate ...   \n",
       "\n",
       "   target                                     question_text_  \n",
       "0       0                  how can i live fully happier life  \n",
       "1       0  what be the difference between it and computer...  \n",
       "2       0    why a suit be the dress code of business people  \n",
       "3       0  how can you get the earnest money loan for a b...  \n",
       "4       0  why would an atheist care if others celebrate ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Quora[\"question_text_\"] = df_Quora[\"question_text\"].apply(lambda question: clean_text(question))\n",
    "df_Quora.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_Quora['question_text_']\n",
    "target = df_Quora['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Split \n",
    "\n",
    "To avoid Sampling Bias due to Random Sampling, I will split the data using Stratifed Split as the 2 output classes are imbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.1, stratify=target, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - Tf-idf & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tfidf vectors #\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "tfidf_vec.fit_transform(X_train.values.tolist() + X_test.values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(X_train.values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(X_test.values.tolist())\n",
    "\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = Y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(C=5, solver='sag')\n",
    "model.fit(train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_ = model.predict(test_tfidf)\n",
    "Y_pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7900414937759336"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(Y_test, Y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(confusion_matrix(Y_test, Y_pred_), annot=True, ax = ax, fmt='g')\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels([ 'Sincere', 'InSincere']); \n",
    "ax.yaxis.set_ticklabels(['Sincere', 'InSincere']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the best threshold based on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11481361, 0.3053329 , 0.05454121, ..., 0.08432779, 0.01435933,\n",
       "       0.01512414])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict_proba(test_tfidf)[:,1]\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.7131101341449667\n",
      "F1 score at threshold 0.12 is 0.7438995498696991\n",
      "F1 score at threshold 0.14 is 0.7654503010197813\n",
      "F1 score at threshold 0.16 is 0.7802350562365727\n",
      "F1 score at threshold 0.18 is 0.7932291666666665\n",
      "F1 score at threshold 0.2 is 0.8024986709197235\n",
      "F1 score at threshold 0.22 is 0.8108621860149355\n",
      "F1 score at threshold 0.24 is 0.8174757281553398\n",
      "F1 score at threshold 0.26 is 0.8219332956472584\n",
      "F1 score at threshold 0.28 is 0.8253877082136704\n",
      "F1 score at threshold 0.3 is 0.8241132681360386\n",
      "F1 score at threshold 0.32 is 0.8222024339566637\n",
      "F1 score at threshold 0.34 is 0.8233173076923077\n",
      "F1 score at threshold 0.36 is 0.819926873857404\n",
      "F1 score at threshold 0.38 is 0.8157528957528957\n",
      "F1 score at threshold 0.4 is 0.8109631949882538\n",
      "F1 score at threshold 0.42 is 0.8084230525649145\n",
      "F1 score at threshold 0.44 is 0.8054356514788168\n",
      "F1 score at threshold 0.46 is 0.8011639185257032\n",
      "F1 score at threshold 0.48 is 0.7967905682004257\n",
      "F1 score at threshold 0.5 is 0.7900414937759336\n",
      "F1 score at threshold 0.52 is 0.7824035058149335\n",
      "F1 score at threshold 0.54 is 0.7739948674080409\n",
      "F1 score at threshold 0.56 is 0.7641853201457575\n",
      "F1 score at threshold 0.58 is 0.7539710554182846\n"
     ]
    }
   ],
   "source": [
    "for thresh in np.arange(0.1, 0.60, 0.02):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(Y_test, (Y_pred>thresh).astype(int))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are getting a better F1 score of 0.824 for this model at 0.3!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
